Better, Faster, Cheaper, Safer: The March of Labor-
Saving Technology
Chapter 1: The Printing Press Revolution
Woodcut (1568) of an early printing workshop, with a printer at the press and assistants inking type and setting
pages.
In a candle-lit scriptorium of the 15th century, rows of scribes hunched over manuscripts, meticulously
copying texts by hand. Books were rare and precious; producing a single volume could take months of
steady  labor .  Into  this  world  burst  Johannes  Gutenberg’s  movable-type  printing  press  around  1440,  a
machine poised to outperform scribes in  speed, cost, and output . Gutenberg’s innovation – metal type
that could be rearranged and reused – enabled a single press to print hundreds of copies far faster than
any team of monks. By 1500, presses across Western Europe had produced more than 20 million volumes ,
a staggering leap from the manuscript era . This explosion of output meant that the  printing press
decisively outperformed human copyists  on the benchmarks of faster and cheaper reproduction. Once
the press proved its efficiency, the economic inevitability of labor substitution set in: the old profession of
the monastic scribe rapidly declined  as printing houses proliferated. 
Tasks Replaced:  The immediate victims of Gutenberg’s device were the scribes and copyists who had long
monopolized book production. For centuries, literate clerics and lay calligraphers earned their living by
hand-copying religious texts, legal documents, and literature. The printing press  swiftly undercut this
livelihood . A single print shop with a handful of trained pressmen and apprentices could produce in a day
what might have taken a scribe weeks. In early print centers like Venice and Paris, former scribes often
1
1
transitioned into new roles  – some became typesetters, printers, or proofreaders, adapting their literacy
skills to the new technology. Others, however , were left behind, their once-valued calligraphy rendered
economically obsolete. By the late 1400s, the demand for handwritten books had collapsed in most of
Europe. One measure of this transformation is the tenfold increase  in book output during the 16th century
(from 20 million copies to as much as 200 million) . No guild of scribes, however proud, could hope to
compete with that productivity. 
Resistance and Regulation:  Not everyone welcomed the printing revolution.  Institutional and cultural
resistance  flared up in various forms. In some regions, authorities feared that the spread of printed
pamphlets and books could undermine religious and political control. Notably, in the Islamic Ottoman
Empire, the introduction of printing was actively suppressed for centuries. Sultan Bayezid II in 1485 (with
the endorsement of religious scholars) banned printing in Arabic script , reportedly on pain of death
. This edict, bolstered by a subsequent 1515 decree from Sultan Selim I threatening execution for
anyone “occupying oneself with the science of printing” , was intended to protect the tradition of hand-
copied Islamic texts and the authority of the calligraphers and clergy. Indeed, when a bold visionary,
Ibrahim Müteferrika, finally established the first official Turkish printing press in Istanbul in 1727, he faced
fierce  opposition  from  guilds  of  calligraphers  and  parts  of  the  religious  ulama .  Such  resistance
delayed the press’s impact: Müteferrika’s press was permitted to print only secular works (no Qur’ans), and
it produced just 17 books before shutting down in 1742 . Similarly, in Europe’s early decades of printing,
there were instances of pushback. In Moscow in 1574, a group of disgruntled clerics and scribes allegedly
set fire to a print works , seeing it as a threat to their positions . Yet these were temporary setbacks.
Overall, European rulers more often  embraced the press  – granting printers privileges and patents –
recognizing  its  power  to  spread  both  knowledge  and  their  own  decrees .  It  was  this  top-down
encouragement that helped the printing press spread rapidly in Europe, whereas the Ottomans’ top-down
ban kept printing at bay for nearly 300 years . 
Timeline of Adoption:  The timeline of printing’s labor substitution can be charted by the declining fortunes
of scribes. Gutenberg’s first major printed work, the 42-line Bible , appeared in the 1450s. By 1470, printing
presses were operating in most major European cities, and by 1500, as noted, millions of books  circulated
where only thousands had before . Within a generation, the cost of books plummeted; a Bible that
would have cost a monk years to copy could now be bought for a fraction of that cost. In centers like Venice,
the printing trade boomed, and professional scribes either found themselves out of work or catering only to
elite  tastes  (like  commissioned  illuminated  manuscripts).  The  substitution  was  not  instantaneous
everywhere – some more remote or conservative institutions clung to handwritten scrolls for a time. For
instance, well into the 16th century, the Vatican was still employing monks to hand-copy certain documents
for tradition’s sake. In the Ottoman Empire, the timeline was dramatically delayed:  only in 1727  did an
official  press  begin  printing  in  Arabic  script  (and  even  then,  as  mentioned,  religious  texts  remained
forbidden) . It wasn’t until the 19th century that printing presses became truly widespread in the
Middle East. In East Asia, where woodblock printing had existed for centuries, movable-type presses were
slower to take hold due to character complexity and existing methods – another kind of lag in adoption. But
eventually, the economic logic won out : where printing presses delivered books “better , faster , cheaper ,”
the old ways gave ground. 
Reasons for Delay:  Several factors could delay the substitution effect of the press.  High initial costs  of
presses and type meant early printing required significant capital or patronage; only wealthy sponsors or
commercial risk-takers could start print shops. This partly explains why early printers often enjoyed noble
patronage (for example, the first press in France was set up under royal auspices ). In places without1
2
3
4
5
5
67
89
1011
1
212
13
2
such support, printing spread slower .  Cultural attitudes  also mattered: in societies where reverence for
calligraphy or fear of uncontrolled information ran high, authorities chose to retard printing’s spread (as in
Ottoman lands). Technical hurdles  were another reason – for languages like Arabic, adapting movable type
was more challenging, which, combined with opposition, slowed development of suitable presses. But these
obstacles  were  gradually  overcome.  When  the  balance  tipped  –  as  local  artisans  learned  the  new
technology, costs fell, and more leaders observed Europe’s gains from print – adoption accelerated. By the
19th century, even the Ottoman state set up modern printing presses and printing became commonplace. 
Steady-State Residual Jobs:  Did the printing press utterly destroy the scribe’s craft? In the mass market,
yes  –  the  professional  copyist  virtually  vanished.  Yet  residual  niches  remained.  In  the  centuries  after
Gutenberg,  calligraphers  carved  out  a  new  steady  state  by  specializing  in  what  machines  could  not
replicate: artistry and personalization. Lavishly illuminated manuscripts  and decorated calligraphic pieces
became luxury art objects rather than everyday fare. To this day, religious scriptures like the Qur’an are
sometimes hand-copied by skilled calligraphers as a sign of devotion, a practice harking back to pre-print
traditions. Fine wedding invitations or diplomas may feature hand calligraphy for its aesthetic cachet. In
essence, the scribe’s occupation transformed from a common trade to a niche art. Printing itself spawned
new jobs: typesetters, printers, publishers, booksellers  – an entire industry of labor grew around the new
technology,  even  as  the  old  copying  jobs  disappeared.  And  centuries  later ,  in  a  nostalgic  twist,  some
aficionados  revived  letterpress  printing  as  a  craft,  keeping  a  touch  of  the  old  techniques  alive  (albeit
powered by passion rather than economic necessity). 
Historical Insights:  The saga of the printing press underscores how a technology that is  demonstrably
superior  in output and cost will eventually upend entrenched labor , despite resistance. It also highlights a
pattern: authorities can delay but usually not indefinitely halt such shifts. The Ottoman Empire’s long ban
on printing, for example, is often cited as a factor in its stagnation relative to Europe . Europe’s
embrace of print, conversely, is linked to the Renaissance, Reformation, and scientific revolution – broader
transformations that printing inadvertently fueled. For labor , the printing press story is a mix of tragedy and
opportunity. To the scribe put out of work, this invention was a personal disaster . But it also dramatically
lowered the cost of knowledge , setting the stage for more educated populations and new professions.
This duality – immediate job loss, coupled with broader societal gain – would recur in subsequent episodes
of labor substitution through technology. As we turn to the mechanization of agriculture, we will see similar
themes play out on an even larger human scale.
Chapter 2: Mechanizing the Fields – From Plow to Tractor
In the mid-19th century American Midwest, vast wheat fields waved under the sun as farmhands swung
their scythes from dawn to dusk. Harvest time was a race against the weather , demanding dozens of
laborers to cut and gather grain before rot or storms set in. This age-old scene began to change in the
1830s when Cyrus McCormick’s mechanical reaper  clattered onto the scene. His horse-drawn contraption
could  slice  through  wheat  fields  far  faster  than  a  team  of  men  with  sickles,  heralding  a  new  era  of
agricultural productivity. By the early 20th century, the internal combustion tractor  further revolutionized
farming – replacing not only human muscle but also horse and ox power . The thesis of “better , faster ,
cheaper , safer” was vividly illustrated on the farm: machines could plow deeper , reap quicker , and work
longer hours than flesh-and-blood workers or draft animals. Slowly at first, then with gathering speed,
farmers embraced mechanization. As they did, the agricultural workforce shrank dramatically , freeing
millions of people from farm labor – whether willingly or not – to find new livelihoods in cities and factories. 14 3
3
Tasks and Jobs Transformed:  Mechanization in agriculture targeted the most labor-intensive farm tasks .
Plowing, once done by the straining effort of horses or oxen guided by a plowman, was taken over by steam
tractors in the late 1800s and then gasoline-powered tractors in the 1900s. Harvesting, which had required
entire villages working with scythes, was first accelerated by the McCormick reaper (capable of doing the
work of several men) and later by the combine harvester , which could reap and thresh grain in one pass.
These machines effectively  substituted capital for labor  – a single farmer with a tractor and modern
equipment could cultivate acreage that previously would have required a dozen farmhands. Over decades,
the traditional farm laborer, stable hand, and plowman  saw their roles erode. The United States offers a
dramatic example: in 1900, about 41% of the American workforce was employed in agriculture; by 2000,
that share had plummeted to around 2% . That steep decline reflects millions of jobs shed – or rather ,
transformed – by mechanization. A typical Midwestern family farm that in 1900 might have needed ten
people and a dozen horses to operate could by 1950 be run by a couple of people with a tractor , and by
2000 perhaps by one person with GPS-guided machinery. Horse breeders and blacksmiths  also saw their
trades  wither  as  “horseless”  farms  became  the  norm.  The  ox-team  driver  and  the  seasonal  migrant
harvester similarly found less demand for their muscle power . Each technological leap – from the first
horse-drawn reapers to the modern GPS-guided combine – narrowed the scope of human labor needed on
the farm. 
Resistance and Skepticism:  While the advance of farm machinery seems inexorable in hindsight, it met
pockets of resistance and hesitance . Unlike the more famous Luddite rebellions in textile mills, farmers
rarely rioted against tractors – but they did exhibit skepticism and caution. In the 19th century, many small
farmers were initially reluctant to trust mechanical reapers , preferring the tried-and-true sickle for fear
the machine might break down at a critical moment. There were reports of farm workers eyeing the new
reapers  warily,  knowing  that  widespread  adoption  could  threaten  their  seasonal  employment.  Some
resistance was practical: early machines were expensive and sometimes difficult to operate or repair . A
farmer of modest means in 1880 might reasonably decide that hiring a few extra hands at harvest was safer
than investing in an unproven, costly machine that could jam or upset the horses. Even into the early 20th
century, cultural attachment to animal power  slowed tractor adoption – many farmers had generations
of know-how in raising and working horses, and the idea of replacing all that with a sputtering machine
took time to gain acceptance. The most notable “resistance” came in the form of delayed adoption  rather
than organized protest. One exception to the quiet transition was the case of the Amish and other tradition-
minded communities, who consciously rejected motorized farm equipment on religious grounds. Their
farms became living examples of a path not taken  by mainstream society – labor-intensive but sustaining a
way of life. However , these were small islands. On a broader scale,  economic reality won out : when
neighboring farms adopted tractors and increased their yields and profits, holdouts eventually had to follow
or fail. 
That said, industrial societies did grapple with the social impact. As millions of farm laborers were no longer
needed, questions arose: where would they go? In the early 20th century U.S., many displaced farm workers
(including sharecroppers and their families) migrated to cities or to newly irrigated lands out West. The
Great Migration of African Americans from Southern farms to Northern cities in the 20th century had many
causes,  but  mechanization  of  cotton  and  tobacco  farming  was  a  significant  one.  Occasionally,  policy
debates  sparked resistance to total mechanization – for instance, during the Great Depression of the 1930s,
when rural unemployment was high, some argued for labor-intensive projects to keep people working on
the land, rather than replacing them with machines. Yet, once the economy picked up and wartime labor
shortages hit in the 1940s, even more conservative farmers turned to machines as a necessity. 15
4
Timeline and Narrative Arc:  The mechanization of agriculture unfolded over more than a century. Key
milestones mark the narrative arc of substitution :
1830s-1850s: Mechanized reaping and threshing.  McCormick’s reaper (patented in 1834) and other
harvesting machines spread slowly at first. By the 1850s, thousands were in use in the U.S. and
Europe, significantly reducing the labor needed for grain harvests. Still, before the Civil War , horse-
drawn reapers were mostly on larger farms; small farms continued manual harvesting for a while. 
1870s-1900: Steam tractors and the dawn of engine power.  The first steam-powered traction
engines appeared in the mid-19th century, used initially for stationary tasks like threshing. By the
1870s, steam tractors that could drag plows existed, but they were heavy, clumsy, and prone to
getting stuck – better suited to the broad flat fields of America than Europe’s small farms. They
demonstrated the concept, though uptake was limited. In the 1890s, innovators like John Froelich
built some of the first gasoline-powered tractors. Still, in 1900 most plowing worldwide was done by
draft animals. 
1900-1930: Gasoline tractors boom.  In the early 20th century, lighter and more affordable tractors
hit the market. Henry Ford’s  Fordson tractor , introduced in 1917, was a game-changer – mass-
produced and relatively cheap, it allowed even mid-sized farmers to retire their horses. Tractor sales
climbed sharply in the 1920s. By 1930, the U.S. had hundreds of thousands of tractors in operation,
and horse populations had peaked and begun to decline . However , the Great Depression
temporarily stalled tractor purchases for many cash-strapped farmers.
1940s-1950s: Post-War acceleration.  World War II created labor shortages (as farmhands went to
war  or  to  higher-paying  factory  jobs),  which  pushed  farmers  to  mechanize  further .  Indeed,
researchers have found that regions were forced  to adopt tractors faster during WWII due to lack of
workers . By 1950, U.S. farms produced more than double the output of 1900 with only a fraction
of the labor . The number of farmers and farm workers was on a steady downward trend. The
1950 census  showed a dramatic drop in farm labor compared to 1900, confirming that millions had
left agricultural work (many permanently) as machines took over . 
1960s-2000: Completing the substitution.  In the late 20th century, even tasks once thought too
delicate or specialized for machines began to be mechanized – from tomato picking (with new
harvester  inventions)  to  dairying  (with  automatic  milking  machines).  The  few  remaining  labor-
intensive niches (like fruit orchards or vegetable picking) also started to see automation by the turn
of the millennium. By 2000, in countries like the U.S., a minuscule proportion of the workforce
sufficed to feed the entire nation and beyond . The labor substitution in farming was essentially
complete: where tens of millions toiled on farms in 1900, only a few million did in 2000 , even as
output hit record highs.
Why the Delays:  If machines were clearly better and faster , why did this process take over a century?
Several reasons emerge.  Economic barriers  were significant: early tractors were expensive, and small
farmers couldn’t justify the cost until prices fell or credit became available. The infrastructure  to support
tractors (like fuel supply, spare parts, mechanics) also needed time to develop, especially in rural areas.
When Henry Ford applied assembly-line techniques to tractor manufacturing (as he had with cars), the price
point dropped, and adoption accelerated. Human and animal adaptation  also had momentum – as long
as labor was cheap and horses readily bred, the incentive to invest in new tech wasn’t overwhelming. For• 
• 
• 
1617
• 
18
19
20
• 
15
5
example, in many developing countries, widespread tractor use didn’t arrive until the later 20th century
when  population  growth  and  land  scarcity  made  intensification  crucial,  or  when  government  policies
subsidized mechanization. Additionally, political factors  sometimes played a role: large landowners might
have mechanized early, but doing so could displace tenant farmers or sharecroppers and cause social
unrest, which some countries tried to avoid for a time. In summary, mechanization needed to reach a
tipping point where its advantages decisively outweighed the traditional system’s familiarity. That point was
reached at different times in different places, but once reached, change was rapid. 
Safer Farming?  One of the “benchmarks” in our thesis is safety. At first glance, one might not consider farm
machinery safer – after all, tractors can roll over and cause fatal accidents, and early machines lacked the
safety features of today’s. However , from a broader perspective, mechanization did improve certain safety
aspects. It  relieved humans from dangerous drudgery : consider that before mechanization, farmers
often suffered chronic injuries (e.g. backbreaking labor , accidents with horses or scythes). Mechanical power
took  on  the  heaviest  and  most  hazardous  tasks  –  pulling  plows  through  stubborn  sod  or  operating
threshing machines where flailing spike-toothed drums separated grain. Over time, as tractor designs
improved (with features like roll bars and power brakes), farming became less deadly than in the horse-
drawn era when a panicking team of horses or a mule’s kick could kill. Moreover , machines don’t feel
exhaustion – a huge factor in farm safety because tired workers are prone to mistakes. So in a real sense,
machines farming “safer” contributed to their inevitability, though the early decades did see many accidents
during the learning curve.
Residual and Niche Roles:  Despite the dominance of machinery, a romantic and practical niche for animal
and human labor  persists. In certain terrains – terraces in mountainous regions, small subsistence plots in
developing  countries  –  hand  tools  or  animal  plowing  still  make  appearances,  often  because  the
landholdings are too small or steep for tractors. There’s also a modern movement of small-scale organic
farming where farmers intentionally use more labor-intensive methods (sometimes even employing draft
horses) as an eco-conscious choice or to produce specialty crops. These represent a voluntary  reintroduction
of labor for specific values, not an economic necessity. Additionally, horses remain present in sectors like
recreational  farming,  tourism  (horse-drawn  carriage  rides) ,  or  cultural  heritage  demonstrations  –
essentially as a nod to history. One particularly poignant residual job is that of  horse logger  in certain
forestry operations, where horses carefully drag logs out of dense woods with minimal ecological damage,
a task where large machines might be too destructive. Thus, even in an age of GPS-driven tractors, there is
a slender steady-state of traditional labor that survives at the margins, either for practical micro-reasons or
as living history. 
Wider Impacts and Insights:  The mechanization of agriculture is often cited by economists as a prime
example of creative destruction . The exodus of labor from farms  was disruptive – millions had to find new
work – but it was also the foundation of modern economic growth. Freed from tilling fields, former farm
workers became the labor force for industrializing cities, filling jobs in factories and services. Society as a
whole benefited through cheaper food  (as mechanization made farming more efficient) and through the
innovation  that  former  farm  folks  brought  to  other  sectors.  Yet,  the  transition  had  hardships:  rural
communities emptied out, sharecroppers in the American South were pushed off the land when cotton
farming was mechanized, contributing to social upheaval. The lesson here is that even when a machine’s
superiority is obvious, the human adjustment can lag and be painful. Importantly, though, the “better ,
faster , cheaper , safer” test was consistently passed by farm machines by mid-century. By 1960, the idea of
returning to manual agriculture was unthinkable in developed countries – it would be economically ruinous
and  practically  impossible  to  feed  the  population  that  way.  When  a  technology  comprehensively
6
outperforms  the  status  quo,  adoption  becomes  a  matter  of  competitive  survival .  A  farmer  who
stubbornly kept using a horse and plow while neighbors used tractors would find his costs too high and
yields too low; eventually, he’d lose his farm or have to change. In this way, the tractor and its kin made
labor  substitution  not  just  likely  but  inevitable  in  farming.  And  thus,  within  a  few  generations,  an
occupation that once dominated human employment became one of the smallest slivers of the labor pie –
an extraordinary economic shift. 
As we leave the fields and turn to the wired world of telephony, we will see a different setting but a familiar
pattern: a new invention emerges that can outperform human workers in repetitive tasks, adoption is slow
at  first  due  to  institutional  inertia,  but  ultimately,  it  revolutionizes  an  industry  and  renders  a  once-
ubiquitous job nearly extinct.
Chapter 3: Wires and Switchboards – Automating the Telephone
Exchange
In a bustling city telephone exchange circa 1910, a visitor would witness a peculiar human hive: along a wall
of plugboards sat dozens of young women with headsets, calmly saying, “Number , please,” as lights blinked
and lines buzzed. These switchboard operators , often called the “Hello Girls,” were the indispensable heart
of early telephone networks. Every call went through them – a customer would crank their phone or pick up
the receiver to signal, and an operator would physically connect the circuit by plugging in a cord. It was an
intensely manual, labor-centric system. Yet, even as operators became a symbol of modern communication,
the seeds of their replacement had already been planted. In 1888, an inventor named Almon Strowger ,
frustrated by the local operator’s bias (legend has it she was routing calls to his competitor , anecdotally
because  she  was  the  competitor’s  wife),  designed  the  first  automatic  telephone  exchange .  This
electromechanical marvel could switch calls using electrical signals and a series of clicks – no human hands
needed.  By  the  mid-20th  century,  automatic  exchanges  had  largely  taken  over ,  making  the  once
ubiquitous switchboard operator a rarity. The journey from manual to automatic switching is a story of
technology  surpassing  human  operators  in  speed,  efficiency,  and  reliability ,  but  one  marked  by
decades of coexistence and resistance before the ultimate substitution occurred. 
The Replaced Role:  The job of the telephone switchboard operator  was a creation of the telephone era
itself (starting in the 1870s) and reached its zenith in the early 20th century. Typically female (after early
experiments  with  male  operators  proved  less  satisfactory),  these  operators  performed  a  complex,
multitasking dance of connecting calls. They had to memorize hundreds of plugs and lines, deftly connect
cords, monitor call durations, and even provide information services to callers. At its peak, this occupation
employed vast numbers – by the 1940s, hundreds of thousands of women worked as telephone operators
across the United States and beyond. It was, for many young women, one of the few socially acceptable
white-collar jobs. Over time, however , machine switching proved it could do the core task – connecting
calls – faster and cheaper . The automatic exchange could handle calls in seconds that might take a human
half a minute, and it could work 24/7 without breaks. One early automatic switch was installed in 1892 in La
Porte, Indiana , but this was more a demo than a takeover . Only by the mid-20th century did these
systems  mature  enough  to  handle  city-scale  phone  traffic  reliably.  When  they  did,  the  impact  on
employment was dramatic. The rank of “telephone operator ,” once a stable middle-class job,  dwindled
steadily . From the 1950s onward, each new central office switch converted to automatic meant dozens
fewer  jobs.  By  the  1980s,  the  role  was  largely  ceremonial,  limited  to  directory  assistance  or  hotel21
2223
7
switchboards. Today, outside of niche contexts, the job of manually connecting calls is virtually extinct –
replaced by digital routing algorithms that owe their lineage to Strowger’s clacking mechanical switches. 
Why They Lasted So Long – Resistance and Inertia:  Interestingly, the substitution of machine for human
in telephone switching was not immediate, even after the invention was proven . Telephone companies
and the public exhibited a form of resistance born not of riots or bans, but of economic calculation, service
quality, and corporate strategy. The Bell System (AT&T) , which controlled most telephony in the U.S., was in
no rush to eliminate operators. One reason was that operators provided a valued personal touch  – they
were early “intelligent assistants,” performing tasks beyond just connecting calls . An operator in the
1910s might know all the customers on her line by name, help forward messages, provide the correct time
or weather , and generally add value  to the service that a cold, mechanical exchange could not match .
Bell executives saw this as a competitive advantage and were loath to make customers dial themselves. As
one  historian  noted,  Bell  believed  automated  dialing  “put  more  of  the  work  onto  the  customer” ,
whereas  an  operator  made  using  the  phone  seamless  for  subscribers.  There  was  also  the  matter  of
investment  in  infrastructure :  Bell  had  built  a  huge  system  of  manual  exchanges  and  had  a  trained
workforce. They weren’t going to scrap that overnight, especially when the initial automatic systems had
kinks and couldn’t handle complex urban networks right away. Indeed, as late as 1910 – nearly two decades
after Strowger’s invention – only about 300,000 of over 11 million telephones in the U.S. were served by
automatic exchanges . Bell didn’t install its first full automatic office until 1921 , and even that was on
a small scale. It took until the 1920s-1930s for technology improvements and the pressure of growing call
volumes to push the Bell System toward wider automation. 
There was also a form of  corporate resistance  to change driven by monopolistic strategy. AT&T’s Bell
System faced competition in its early years from independent telephone companies, especially in rural
areas. Those independents, with fewer resources to hire and train operators, were more keen to adopt
automatic switching to save costs. They touted automation’s benefits – privacy (no operator eavesdropping),
speed, and fewer wrong connections . Bell, defending its turf, countered by emphasizing its superior
service  with  human  operators  and  by  leveraging  its  control  of  long-distance  lines  to  disadvantage
competitors . In effect, Bell slowed the spread  of automation where it could, to maintain a consistent
service image and keep operators employed on its own terms. This strategic resistance prolonged the life of
the operator job in the Bell system well past the point when technology could have replaced it. 
Operators  themselves  and  their  unions  also  played  a  role.  Organized  labor  wasn’t  violently  anti-
automation,  but  they  understandably  sought  to  protect  jobs.  As  automation  loomed  in  mid-century,
telephone unions negotiated for provisions to soften the blow – retraining operators for other roles, or
ensuring gradual phase-outs rather than sudden layoffs. Public sentiment, too, favored these mostly polite
and helpful women who had become part of daily life; there was no public outcry demanding they be fired
in favor of machines. All these factors combined to create a few decades of  coexistence : automatics in
some places, manual boards in others, slowly shifting as economics and technology tipped the balance. 
The Tipping Point – When Substitution Accelerated:  The balance began to shift decisively after World
War II. As telephone usage exploded, especially long-distance dialing, the cost advantages of automation
became  impossible  to  ignore.  Machines  could  handle  increasing  call  volumes  without  proportional
increases  in  staff  –  a  crucial  factor  as  millions  of  new  phones  came  online.  By  the  1950s  and  60s,
electromechanical  and  then  electronic  switches  had  reached  a  level  of  sophistication  and  reliability  to
handle big city networks. One by one, the great urban telephone exchanges – places like New York and
Chicago, which had employed armies of operators –  cutover to dial service . These cutovers often were24
24
25
26 27
28
29
8
momentous events. On a chosen night, engineers would reroute circuits, and in the morning, customers
would wake up to a new dial tone and the ability to dial directly. The operators in those cities might find that
half their boards were dark, their workload permanently reduced. Many were reassigned or let go through
attrition.  For  instance,  New  York  City’s  last  residential  manual  exchange  converted  in  the  1950s,  and
thousands  of  operator  positions  were  eliminated  as  a  result  (though  AT&T  managed  much  through
retirements  and  halting  new  hiring).  By  the  late  1970s,  direct-dial  calling  was  standard  even  for
international  calls,  and  nearly  all  local  exchanges  were  automated .  The  number  of  telephone
operators in the U.S., which had peaked mid-century, went into a steep decline. What had taken over 70
years from Strowger’s invention finally became the norm:  the machine fully surpassed the human in
connecting phone calls , and economics dictated that machines take over almost entirely. 
Forms of Delay and Adaptation:  It’s worth noting how long the  lag was between invention and full
substitution – roughly 80 years from the 1890s to the 1970s. The reasons, as discussed, included corporate
strategy and the fact that, for a time, humans were still “competitive” by providing personalized service. But
technology kept improving. By the 1930s, automatic exchanges worked well enough even for large cities,
yet  the  conversion  still  took  several  more  decades  to  complete.  Part  of  that  was  simply  the  massive
investment  required – changing over millions of subscriber lines and equipment was costly and had to be
scheduled  over  time.  World  events  also  intervened:  the  Depression  and  World  War  II  slowed  capital
spending  on  network  upgrades.  Ironically,  WWII  accelerated  some  changes  (like  in  farming),  but  for
telephones, it postponed upgrades as materials were diverted to the war effort. After the war , the push for
modernization resumed in force. Another subtle delaying factor was  customer behavior  – early on, not
everyone  wanted  to  dial  their  own  calls.  Some  people  found  the  new  dial  phones  confusing  or  were
nostalgic for the friendly operator (“Just get me Main 123”). As older generations passed and younger , tech-
savvy users predominated, this human factor faded away. In sum, the telephone industry’s arc shows that
even if a machine is better , faster , and cheaper , social and institutional factors can slow substitution , but
not stop it indefinitely. Eventually, the sheer efficiency wins. 
Safety and Reliability:  Was automated switching “safer”? In a way, yes. Human operators, though skilled,
could make errors – plugging into the wrong line, mishearing a number – which could misdirect calls or
even create dangerous delays (imagine a missed emergency call). Machines, once matured, provided more
consistent, error-free connections. They also enhanced privacy and security , as customers no longer had
to relay possibly sensitive information to an operator for every call. In terms of job safety, being a telephone
operator wasn’t generally dangerous (though the repetitive stress and sometimes eyestrain were issues), so
“safer” wasn’t a primary driver here as it was in some other substitutions. But reliability – a cousin of safety –
certainly was a driver: automated exchanges never called in sick and never got tired at the end of a long
day, so networks became more robust. 
Residual Roles and Nostalgia:  Though the heyday of switchboard operators is long over , the role did not
disappear completely overnight.  Residual jobs  persisted and, in some cases, still exist. Into the 1980s,
many businesses and hotels retained manual PBX (private branch exchange) boards with live operators to
greet callers and route internal calls – a touch of hospitality that machines couldn’t quite replace then. Even
today, a caller to certain corporate or government numbers might press “0” and reach an  operator or
attendant  (though  often  now  they  are  effectively  customer  service  representatives  rather  than  pure
switchboard operators). Information and emergency operators  remained vital – for many years, people
still dialed “0” to ask for directory information or to have an operator assist with a collect call or an
international connection. These functions gradually got automated as well (with computerized directory
systems and international direct dialing), but a core remained. For example, 911 emergency dispatchers3031
9
are a modern incarnation of an “operator” – while they don’t manually connect circuits, they serve as human
intermediaries in urgent situations (and as of now, machines haven’t supplanted the need for human
judgment and reassurance in that role). In a charming nod to nostalgia, a few places maintain live manual
exchanges as historical exhibits. And certain elite institutions (like the White House) long kept manual
switchboards staffed by operators for a personal touch , though even those have largely transitioned to
modern systems now. 
Historical Perspective:  The automation of telephone switching highlights how a technological substitution
can be drawn out by non-technical factors . Unlike the printing press or tractor , where improvements were
visibly drastic, the automatic switch had to prove itself over decades, and its adoption was governed by a
monopoly  that  weighed  more  than  raw  efficiency.  Yet,  the  end  result  was  the  same  type  of  labor
displacement : a job category that once employed hundreds of thousands virtually vanished. It’s also an
example of how a new technology can simultaneously create new kinds of jobs  even as it destroys others.
The telephone industry’s growth created installation technicians, linemen, engineers, and, yes, operators.
When the operators dwindled, other roles – like electronic technicians and computer programmers for the
new exchanges – expanded. Society also had to manage the transition: many operators moved on to other
clerical jobs, often aided by the fact that their employment had given them skills and confidence in the
workplace (indeed, being an operator was a stepping stone into the workforce for many women, who later
became secretaries, supervisors, or entered entirely different careers). 
In the narrative of “better , faster , cheaper , safer ,” the telephone switch is an interesting case because better
didn’t just mean faster dialing; it also meant a new level of customer empowerment  (dialing direct) and
network scalability. When millions more phones had to be connected, hiring millions more operators wasn’t
feasible – automation was the only way to scale up communications. Thus, one can see that under the
pressure of growth, the machine’s advantages became overwhelming. By the time digital electronics arrived
(the  1970s  and  80s  brought  computer-based  switches),  the  last  arguments  for  any  human  mediation
evaporated. Today’s global internet-based communication networks route billions of connections without
any manual intervention – a far cry from the plug-and-cord days. The switchboard operator’s story reminds
us that even cherished human-centered roles can become economically unsustainable once technology
reaches a certain threshold of capability. It’s a lesson that will resonate as we next examine how typewriters
and  office  automation  impacted  clerical  work,  and  later ,  how  computers  and  AI  challenge  roles  once
thought safe from automation.
Chapter 4: Typewriters, Computers, and the Office Clerk –
Automating the Office
Picture a late 19th-century office: rows of high desks at which clerks stand or sit on stools, quill pens
scratching on paper ledgers, copying letters into big bound books. In one corner , perhaps, a  “copyist”  –
usually a young man – laboriously handwrites duplicates of correspondence for company files. This was the
world of office work before the machine age, often depicted in Dickens’ novels with characters like Bob
Cratchit or the legion of scriveners. It was time-consuming and demanded neat penmanship and patience.
Then, in the 1870s, a new contraption began to appear on desks – the typewriter . With keys to tap and ink
to  transfer  letters  onto  paper ,  the  typewriter  promised  to  greatly  speed  up  writing ,  ensure  uniform
legibility, and allow carbon copies for the first time. By the early 20th century, typewriters were as integral
to offices as telephones, and they had profoundly changed who did clerical work and how. The humble
typewriter was the forerunner of a broader office automation revolution  that would later include word32
10
processors, computers, and software – all technologies that sequentially substituted machines for human
labor in routine office tasks . The introduction of the typewriter and its successors is a story not just of
productivity, but also of social change: it opened the office door to women workers, disrupted traditional
clerical career paths, and eventually made certain job titles (like “dictation secretary” or “typing pool clerk”)
fade away entirely. 
Specific Tasks and Roles Replaced:  The typewriter’s arrival in the late 19th century directly threatened the
jobs of  professional copyists and clerks  who specialized in neat handwriting. Previously, every letter ,
invoice, and memo was handwritten – either by the author or by an employee tasked with fair-copying
drafts. In legal offices, law clerks spent endless hours copying legal documents; in business, clerks kept
accounts and copied correspondence into record books. The typewriter  transformed this workflow . A
trained typist could outpace a hand scribe by a significant factor – e.g., 60+ words per minute versus
perhaps 20 by hand – and produce multiple carbon copies at once, eliminating the need for separate
copying steps . Thus, one typist with a machine could do the work that might have required two or
three clerical copyists before. The immediate effect wasn’t mass unemployment of clerks; rather , offices
handled more volume with fewer people and redeployed staff to other duties. Over a couple of decades, the
nature of office jobs shifted:  male clerks  who once expected a steady career making ledger entries saw
those routine writing tasks either automated or passed to new entrants (often women) who mastered
typing. By the early 20th century, the job title “typewriter” referred not just to the machine but to the person
operating it – and these “typewriters” were overwhelmingly  young women . Indeed, the typewriter was
instrumental in creating the role of the secretary/steno typist , a job category that expanded enormously.
It wasn’t so much that all clerical work vanished, but it was repartitioned : the grunt work of putting words
on paper could be done by a pool of fast typists, enabling executives and professionals to focus on content
and decision-making. Later on, as office automation continued, even those typist roles would be thinned
out – for instance, when the personal computer arrived in the 1980s, many managers began typing their
own emails and documents, effectively doing away with the need for an intermediary typist for everyday
writing. Ultimately, the cascade of technology – typewriter , then word processor , then PC and printer –
eliminated the once-common position of “company typist” or “dictation secretary” . The typing pools
that were a fixture of mid-20th-century corporate life (rooms full of typists clattering away at company
memos and forms) were largely gone by the 1990s, a victim of the next wave of automation. 
Resistance  –  Tradition,  Fears,  and  Gender  Dynamics:  The  adoption  of  the  typewriter ,  like  many
innovations, met with initial resistance and skepticism . In the 1870s and 1880s, some business owners
and government officials were hesitant to trust important documents to a machine. “Tradition-bound critics
opposed the use of typewriters on legal and even health grounds,” notes one account . There were
claims  that  typewritten  documents  weren’t  as  official  or  would  not  be  accepted  in  courts  (a  concern
gradually allayed as typed contracts and filings proved their worth). Some even argued that operating a
typewriter could be harmful – perhaps citing eye strain or the jarring motion of early models – though such
health concerns were marginal. More significant was the cultural and workforce resistance : at the time,
clerical jobs were a male preserve. Introducing typewriters effectively changed the skill set required for
clerical work, and many male clerks  resisted retraining  to learn typing, which they viewed as menial or
technically vexing. As one historian put it, most men in clerical roles “weren’t willing to adjust to this radical
technology and found the typewriter too hard to understand and use effectively” . This opened the
door for women (who had been excluded from most office jobs) to be hired as typists, since employers
found women willing to learn and, frankly, willing to accept lower pay . There was indeed resistance from
the male-dominated clerical establishment – some feared (rightly) that women with typewriters would3334
35
3637
11
replace them. In some cases, offices were slow to adopt typing because the senior clerks or managers
simply didn’t want to upset the status quo of how work was done. 
The transformation thus carried a strong gender dimension . When women began entering offices in the
1880s and 1890s as typists, it was a social novelty. Pioneering female typists were sometimes met with
condescension or the assumption that they’d just work until marriage. Yet they proved themselves highly
capable and by the 1910s were indispensable in most large offices. Some resistance took the form of office
folklore and sexism  – for example, the archetype of the “typewriter girl” became glamorized in media, but
real female typists often faced wage disparities and no promotion track . Male managers enjoyed the
productivity gains but ensured that these women remained in subordinate roles (the boss would dictate a
letter to his secretary rather than type it himself, even if he knew how). Thus, the resistance was not so
much to the machine itself after its efficacy was clear , but to its  implications for workplace dynamics .
Over time, however , the sheer efficiency of typed documents won out. By 1900, even reluctant institutions
like government bureaucracies were buying thousands of typewriters annually . An amusing anecdote:
Mark Twain was one of the first authors to submit a typed manuscript to a publisher (in the 1880s) ,
which no doubt raised eyebrows but also proved that the new machine could handle even literary work. 
Timeline of Substitution:  The typewriter’s spread and the consequent labor shift happened over a few
decades. The first commercial typewriters (the Sholes & Glidden “Type-Writer” marketed by Remington)
came out in 1874 , but sales were slow – only a few hundred sold per year initially . It wasn’t until the
1880s  that annual sales exceeded a thousand, as improvements made the machines more user-friendly and
durable .  By  the  1890s,  multiple  manufacturers  (Remington,  Underwood,  Smith  Premier ,  etc.)  were
producing  typewriters  and  aggressively  marketing  them.  A  critical  mass  was  reached  where  large
businesses and government offices began standardizing on typed documents. As one source notes, the U.S.
Department of Agriculture got its first machine in 1878 (an early adopter for a government agency), and by
1900 the federal government was ordering typewriters by the tens of thousands . 
So 1890-1910  was the pivotal period when typewriters went from novelty to necessity in the office. During
that time, the workforce composition in offices tilted heavily toward women: in 1870, women were virtually
absent from clerical jobs; by 1900 tens of thousands and by 1930 millions of women were working as
secretaries, stenographers, and typists . This was a direct outcome of the typewriter’s adoption. The
traditional male copy clerk, in effect, was being replaced (or redefined) as a female typist. Some men moved
up to become managers or salesmen, others left for other fields; the pipeline of young women entering
kept clerical wages modest and the adoption of typing economically attractive to employers. By World War
I, virtually every office task that could be mechanized in terms of writing was – all correspondence, reports,
and records were expected to be typed. The fountain pen lingered only for personal notes or signatures. 
The next phase,  office automation , took off mid-20th century with  electromechanical innovations  like
dictation  machines  (letting  bosses  record  letters  for  secretaries  to  transcribe  via  headphones),
mimeographs and later photocopiers (automating copying tasks), and eventually the  computer . In the
1960s-1970s ,  early  word  processors  (like  the  IBM  Selectric  typewriter  with  magnetic  tape,  and  later
standalone  word  processing  computers)  started  to  eat  into  the  typing  pool.  A  single  word  processor
operator could handle editing and printing tasks far more efficiently, and repetitive typing (like form letters)
could be generated from templates, reducing labor . By the 1980s and 1990s , personal computers on every
desk completed this substitution arc. Now many executives or professionals type their own emails and
documents on PCs – something that would have been done by a secretary in 1950. Consequently, the
number of secretaries and office clerks in advanced economies plateaued and even declined late in the 20th38
39
40
41
41
39
42
12
century. The role of “typist” essentially vanished ; those in administrative support now do a broader range
of tasks (scheduling, communications, etc.), with pure typing no longer a specialized skill. 
Reasons for Any Delay:  Compared to some technologies, the typewriter’s rise was relatively swift, but there
were a few bumps. Early machines had technical limitations – the first typewriters were “blind” (you couldn’t
see what you just typed until you lifted the carriage), they jammed easily if you typed too fast (hence the
QWERTY keyboard layout was designed partly to slow typists down to avoid jams), and some people found
them awkward compared to the flow of handwriting . These issues were steadily improved (the
visible typewriter by the 1890s, better engineering reducing jams, etc.). Another initial hurdle was training :
typing is a skill that requires practice, and until typing classes became common, some offices hesitated to
invest in machines that their staff couldn’t use efficiently. This created a bit of a chicken-and-egg problem
solved by the rise of  business schools and typing courses , and by companies like Remington offering
training sessions. By 1900, one could hire graduates (often young women) who had learned touch typing in
school – a new pipeline of labor that eased adoption. Cost was less of an issue; typewriters weren’t cheap
(maybe $100 in 1880s dollars, a substantial sum ), but for businesses, the productivity gain usually
justified the expense after a short time. 
Some amusing forms of resistance were simply  habitual : older professionals who prided themselves on
fine penmanship derided typewritten letters as impersonal or “ugly.” In some elite circles, handwritten
letters  remained  a  mark  of  class  for  a  while.  But  those  sentiments  faded  as  typewriters  themselves
improved  in  producing  clear ,  elegant  type,  and  as  people  associated  typed  documents  with  modern
efficiency.  In  the  legal  realm,  once  legislation  and  court  rules  embraced  typed  filings,  any  remaining
holdouts had to comply or risk their documents being rejected for illegibility. 
Steady-State Survivors:  Even as typewriters took over offices, a few niche roles for hand-copied or hand-
crafted text  persisted (and still persist). Calligraphers, much like after the printing press, found niche
demand for decorative writing – for instance, engrossing official certificates, diplomas, or invitations. Some
lawyers continued to draft wills or deeds in longhand into the mid-20th century, valuing the personal touch
or simply by personal habit, though a clerk would usually type a clean copy afterward. As for typewriters
themselves, they’ve ironically become a niche item in the 21st century: cherished by collectors, used by
certain writers or nostalgists who prefer the  tactile, distraction-free experience . There are even a few
public figures and authors today who draft on typewriters for personal preference, demonstrating that old
technologies can survive in the corners of culture even after being commercially outmoded. In terms of
jobs,  the  “secretary”  occupation  did  not  disappear  –  but  it  evolved.  The  role  today  is  far  more  about
coordination, communication, and using digital tools, versus the pure typing and shorthand that defined it
in 1920. 
One interesting steady-state phenomenon is that some high-level executives kept personal secretaries
even  late  into  the  PC  era ,  not  because  they  couldn’t  type,  but  to  delegate  scheduling,  field
communications, etc. However , the vast middle tier of managers now often handles their own typing. So the
residual is more at the high end (executive assistant roles) and at the specialized end (e.g., court reporters
who use stenotype machines to transcribe speech in real time – an example of a job where a person with a
machine still outperforms available fully-automated solutions in accuracy, though even that is being tested
by voice recognition AI now). 
Unique Insights from the Office Automation Story:  The introduction of the typewriter and later office
machines carries a few unique lessons. First, it shows how technology can be a catalyst for social change4344
45
13
(in this case, women’s entry into the workforce). The machine didn’t inherently care about the operator’s
gender , but societal context shaped how it was adopted, with profound consequences. Second, it underlines
the notion that skills and workforce adaptation  are crucial. The typewriter didn’t eliminate the need for
human labor in offices; it changed the  skills required  – from penmanship to typing, from copying to
organizing information. Workers who adapted thrived, those who didn’t were left behind. This pattern
repeats  with  computers  –  clerical  workers  who  learned  word  processing  and  spreadsheet  software
remained valuable, while those who stuck to typewriters eventually had little choice but to retire or retrain. 
From  a  pure  economic  standpoint,  the  typewriter  was  an  early  example  of  information  technology
improving productivity . By cutting down the time to create and duplicate documents, it contributed to the
massive expansion of bureaucracies and corporations in the 20th century – paperwork could keep up with
the  growth.  The  fact  that  by  the  1960s,  you  needed  entire  typing  pools  to  manage  corporate
communication also set the stage for the next disruption: computers that could do the same work with
even fewer people. 
In summary, the typewriter chapter in labor substitution illustrates that once a machine offers even a
seemingly modest improvement – a letter that might take an hour to write by hand can be done in 20
minutes typed – it can trigger large ripple effects in how work is structured. Over time, those ripples
fundamentally altered the labor landscape of offices worldwide. As we proceed to “industrial sewing,” we
will look at a technology that arrived even earlier than the typewriter and likewise redefined a major
employment sector , especially for women: the sewing machine and the garment industry.
Chapter 5: The Sewing Machine and the Fabric of Work
Before the 19th century, every stitch in every garment was made by hand. In dim cottages and crowded
workshops, seamstresses and tailors  sewed tirelessly, needle and thread in hand, producing clothing one
piece at a time. The advent of the  sewing machine  in the mid-1800s was as revolutionary for garment-
making as the printing press had been for books. It offered an astounding leap in speed: a seam that might
take 30 minutes to hand stitch could be done in under a minute on a machine. As one early demonstration
showed, a single sewing machine could outperform five of the fastest hand sewers . This technology had
the potential to upend an entire labor sector – and indeed it did. But not without drama and resistance :
the sewing machine’s introduction literally sparked riots. On a larger scale, it transformed the garment
industry from a home-based, labor-intensive craft into a mechanized, factory-driven enterprise. It displaced
many traditional seamstresses, even as it created new jobs in factories and eventually gave consumers
cheaper , more abundant clothing. 
Jobs and Tasks Replaced:  The sewing machine directly targeted the core task of  stitching fabric , which
was the bread and butter of seamstresses (women who sewed for a living, often in their homes or in small
shops) and tailors (who typically made men’s suits and coats by hand). Prior to mechanization, making a
single shirt could involve hours of hand sewing, and garments were often produced by assembling pieces
sewn by several women working in a kind of proto-piecework system. The sewing machine changed the
game by allowing continuous, rapid stitching . Once a worker became adept at using the treadle-powered
machine, she (or he, in some early cases) could finish seams with uniform tight stitches far faster than by
hand. For the garment industry, this meant huge productivity gains. Clothing manufacturers in places like
New York and London eagerly adopted machines in the 1860s and 1870s, dramatically increasing output
without commensurate increases in labor . The impact on labor was twofold:  fewer total hands were46
14
needed  to  produce  the  same  amount  of  clothing,  and  the  locus  of  work  shifted  from  dispersed
homeworkers to centralized factories. 
Take the example of a  shirtwaist factory  around 1900: with machines, a team of operators at sewing
machines could each handle a part of the assembly (one does sleeves, another collars, etc.), turning out
hundreds of garments a day. In the old hand-sewing model, even a dozen seamstresses together might
manage only a few dozen garments in the same time. Thus, many of the independent seamstresses – who
might have eked out a living sewing custom dresses or doing piecework for merchants – found their
services less in demand as  ready-made clothing  (machine-made in factories) became prevalent and far
cheaper .  A  stark  measure  of  change:  between  1860  and  1890,  the  cost  of  clothing  relative  to  wages
plummeted, indicating how much more efficiently apparel was being produced. This was largely due to
mechanization.  Tailoring  was also affected: while the finest bespoke suits still required hand tailoring,
much of the assembly could be sped up with machine stitching, reducing the hours a tailor needed to
spend (and thus reducing how many assistants or apprentices he might employ). Many tailors who clung to
all-hand methods could not compete on price with those who integrated machines for non-visible stitching. 
Resistance – Luddite-Like Rebellion:  The sewing machine, perhaps surprisingly, provoked one of the
earliest  instances  of  violent  resistance  to  industrial  automation .  In  1830,  a  French  tailor  named
Barthélemy Thimonnier patented an early sewing machine and set up a workshop to sew uniforms for the
French Army. The reaction from fellow tailors was swift and fierce: a  mob of tailors, fearing for their
livelihoods, stormed Thimonnier’s workshop, destroyed his 80 machines, and nearly killed him
. This incident in France echoed the Luddite sentiments (though the original Luddites in 1810s England
had targeted weaving machines, not sewing). The message was clear – those tailors perceived the machine
as an existential threat. Thimonnier fled for his life; his invention at that time failed to take hold due to this
and other factors (his early machine was also limited in capability). 
As sewing machines were later reinvented and improved (notably by Elias Howe in 1846 and Isaac Singer in
the 1850s), resistance took other forms. In America, during the early marketing of sewing machines, some
tailors’ guilds and seamstresses  voiced opposition, though no American riots of Thimonnier’s scale are
recorded. Still, there was  initial reluctance  among skilled garment workers to embrace the machines.
Some  of  this  was  fear  of  job  displacement;  some  was  practical  –  early  machines  were  costly,  and  a
seamstress working from home could not afford one outright. Singer’s company famously addressed that
by introducing installment payment plans, making it feasible for individual dressmakers to buy a machine
and thereby remain competitive. Those who did not or could not were often forced out of business by those
who did, or by factories. In Europe, some governments and guilds were slow to adopt sewing machines in
their workshops. The resistance gradually softened as it became evident that sewing machines could also
ease drudgery . For many women, stitching by machine was physically less taxing than hand sewing all day,
though it introduced a different kind of fatigue (foot treadling and intense concentration on a fast-moving
needle). It’s worth noting that once the technology matured, many former opponents were won over by the
productivity boost – if only to keep earning a living. 
Institutional resistance  was not as prominent here as with the printing press, but one could argue that
the sweatshop system  that arose was a form of resistance to complete automation – since not every part
of  garment  making  was  easily  mechanized  (cutting  fabric,  for  instance,  remained  manual  until  later
inventions). Instead of fully automated factories, the late 19th century saw a hybrid: sewing machines run
by human operators in cramped “sweatshops.” The owners of these shops resisted calls for reducing hours
or improving conditions, leveraging the machine-augmented productivity to demand even more output47
48
15
from workers, which led to labor strikes (like the famous garment workers’ strikes in the early 1900s). So in
a  sense,  the  fight  was  no  longer  workers  versus  machines,  but  workers  versus  exploitative  use  of
machines . 
Timeline  and  Adoption:  After  the  false  start  in  1830  France,  the  sewing  machine  made  a  successful
commercial debut in the United States in the 1850s. Isaac Singer’s improvements (foot treadle, straight
needle, etc.) and savvy business practices made his sewing machines wildly popular . By the late 1860s, tens
of thousands of machines were being produced annually. The Civil War in the U.S. (1861-65) gave a big push
– the Union army’s huge demand for uniforms spurred manufacturers to adopt sewing machines to fulfill
contracts  faster .  In  the  post-war  period,  the  concept  of  ready-to-wear  clothing  took  off,  enabled  by
machine sewing. Factories in New York, London, and Paris started producing standard-sized garments for
sale in shops, something that was only marginal before (most clothing was custom-sewn or home-made).
By  1880 , the presence of sewing machines was ubiquitous in garment production. In homes, too, the
sewing machine became one of the first mass consumer appliances . Women who might sew their family’s
clothes  or  do  paid  sewing  from  home  embraced  the  domestic  sewing  machine  –  by  offering  it  on
installment, companies like Singer put a machine in a huge number of households. This meant that even at
home,  the  labor  of  sewing  (which  was  a  major  component  of  women’s  domestic  work)  was  partially
automated. A single woman could produce and mend far more clothing with a machine, reducing the need
to hire seamstresses for basic garments. 
Thus, through the late 19th century, we see a steady labor shift:  independent seamstresses decline ,
factory garment workers increase, and almost every tailor or sewing professional uses machines for at least
part of the work. Tailoring  (for high-end custom suits, etc.) remained partly a bastion of handwork – fine
hand-stitching was and is prized in certain seams or finishing – but even bespoke tailors came to use
sewing machines for long internal seams to save time, reserving handwork for where it truly made a
difference (like canvas shaping in suits, or buttonholes until machines for that came along too). By the early
20th century, even those niches started to shrink as specialized sewing machines (e.g., for buttonholes,
zigzag stitching, embroidery) were invented. 
Delays and Limitations:  The speed of adoption  was affected by a few things. Initially, patent battles  in
the 1850s (Howe vs. Singer vs. others) made it tricky – but that was resolved by a patent pool by 1856 ,
clearing  the  way  for  more  manufacturers  and  innovation.  Cost  was  a  factor ,  but  the  installment  plan
cleverness overcame that for many consumers. Some geographical areas lagged – e.g., rural areas or
poorer countries took longer to get machines widely in use, often not until the 20th century when cheaper
models  or  knock-offs  became  available.  Another  technical  limitation  was  that  early  machines  were  all
human-powered (foot treadles). The introduction of  electric sewing machines  in the early 20th century
(around the 1920s for home use) further boosted productivity and ease (no tiring leg pumping). But those
came after the main wave of substitution. 
What  truly  might  have  slowed  adoption  in  some  quarters  was  the  notion  of  quality .  Early  on,  some
connoisseurs claimed hand stitching was superior in durability or appearance. For example, a haute couture
dress in 1880 might still be mostly hand-sewn because very delicate fabrics or intricate techniques weren’t
easily done on the straightforward lockstitch machines then. Over time, machines diversified with different
stitches and adjustments that could handle more delicate work, but high fashion even today employs hand
sewing for certain finishes. This quality argument, however , did not hold back the mass market – for
everyday wear , machine stitching quality was more than adequate and only got better . 49
16
Residual and Niche Work:  Did any sewing jobs remain or reappear after mechanization? Absolutely – in
fact, the garment industry remained (and remains) labor-intensive in many respects. The sewing machine,
after all, still required an operator; it didn’t eliminate the need for human hands, it just made those hands
vastly  more  productive.  So  rather  than  eliminating  the  workforce,  it  reshaped  it :  instead  of  solitary
seamstresses  sewing  entire  garments,  you  had  lines  of  garment  workers  each  sewing  one  part  of  a
garment with a machine. This was an increase in efficiency but still needed many workers, which is why
garment factories became huge employers , especially of women and immigrants in industrial cities.
That’s an interesting contrast to other automation stories – here the machine didn’t so much remove
humans as concentrate them into factories under harsher conditions (hence the infamous sweatshops).
Over time, further innovations (like automated cutting machines, and later , in recent years, some robotic
sewing attempts) have gradually reduced the number of people needed, but even in the 2020s, apparel
manufacturing remains partly manual – sewing flexible fabric with robots is notoriously hard because fabric
shifts and stretches. So, in a sense, the  steady-state  in garments was a new equilibrium: fewer total
workers  per  garment  produced,  but  still  millions  employed  worldwide,  especially  as  the  market  grew
(everyone could afford more clothes, which somewhat offset the labor saving per item). 
Outside of factory production, tailors and dressmakers  indeed persisted as niche professionals for custom
clothing. The sewing machine became just another tool for them. In wealthy communities or for specialized
attire (wedding gowns, suits), people still paid for hand-fitted garments, and seamstresses continued to find
work in alterations and repairs – tasks not eliminated by machines. Today, while mass manufacturing is
largely done in factories (often in low-wage countries), there’s a minor renaissance of  artisan sewing  –
bespoke tailors on Savile Row in London or custom dressmakers for celebrities still ply needle and thread
(along with their trusty sewing machines) to create one-of-a-kind pieces. And millions of hobbyists sew at
home for pleasure, using sewing machines (or even hand sewing quilting and crafts). 
One could say that the sewing machine  freed sewing from being a dreaded drudgery into more of a
creative or value-added activity  for those who chose to pursue it by choice rather than necessity. After all,
by making clothing cheap and abundant, it was no longer imperative for most women to sew their family’s
clothes to save money – they could buy them. Sewing became something one might do for enjoyment or for
particularly personal projects, rather than a compulsory domestic chore. In this sense, a steady-state job
that nearly vanished was the “household seamstress” – many middle-class families in the 19th century hired
seamstresses to come and sew for weeks to outfit the family. By the 20th century, that job was gone; people
bought ready-made or used their own machine for minor things. 
Historical and Economic Insights:  The case of the sewing machine highlights how labor substitution can
initially cause turmoil  (riots and unemployment for some) but also how it can be absorbed through
industry growth. The garment industry example shows  both displacement and expansion : individual
craftspeople lost autonomy and some lost livelihoods, but many others got jobs in factories, albeit often
under worse conditions initially. It emphasizes a darker side of “better , faster , cheaper” – cheaper clothes
were great for consumers and boosted living standards, but the quest for cheaper also led to exploitation
of labor in new ways , as factories pressured workers to meet the machines’ pace. It wasn’t until labor
movements and regulations (like limits on working hours, safety standards after tragedies like the Triangle
Shirtwaist Factory fire in 1911) that the benefits of the productivity gains were more fairly shared. 
From  a  purely  technological  view,  the  sewing  machine  proved  very  clearly  that  when  a  machine
dramatically outperforms hand labor (5x faster or more) and maintains acceptable quality , it will be
universally adopted in production sooner or later . The initial violence in France can be seen as a 4748
17
futile  attempt  to  hold  back  that  tide  –  once  Singer  and  others  solved  the  technical  and  commercial
challenges, the economic logic won in short order . In fact, sewing machines spread globally. One fun
historical twist: in places like the Ottoman Empire, which had resisted printing presses, sewing machines
were welcomed much more quickly in the late 19th century – an indication that by then, even conservative
societies saw the value in this labor-saving device for textiles (a trade they highly valued). 
Finally, the sewing machine’s story underscores how  substitution doesn’t always mean fewer workers
overall in a sector ; sometimes it allows the sector to produce so much more that prices drop and demand
increases (the classic case of elastic demand ). People bought more clothes when they were cheaper , which
kept employment up even as productivity rose – until globalization and outsourcing later moved those jobs
to lower-cost regions, which is another tale of labor shift. 
As we turn to modern robotics and AI, the stakes seem higher – the jobs potentially affected are not just
manual or clerical but also cognitive. Yet the recurring themes – initial skepticism, gradual improvement,
eventual dominance once clearly superior , and complex effects on the workforce – remain relevant, as we
shall see.
Chapter 6: From the Assembly Line to Algorithms – Robotics and AI
in the Workplace
In a General Motors plant in 1961, a giant one-armed machine called Unimate  began its first day on the job
lifting hot pieces of metal on an assembly line – an unglamorous task, but a landmark moment: the first
industrial robot at work. Fast-forward to today, and factories around the world hum with the coordinated
motions of  robotic arms , welding, painting, and assembling at speeds and precisions no human could
match.  Meanwhile,  in  the  digital  realm,  artificial  intelligence  algorithms  sift  through  data,  answer
customer queries in chat windows, and even draft documents or code. The modern era presents perhaps
the most sweeping potential for labor substitution: machines that can think as well as act , taking on not
only brute physical work but also tasks requiring analysis or decision-making. The core thesis – “better ,
faster , cheaper , safer” – is tested at new heights: can robots and AI truly outperform humans across those
metrics in field after field? Increasingly, the answer appears to be  yes, they can and will , at least for
specific, well-defined tasks. The result is an ongoing and accelerating shift in the labor landscape, one that
echoes earlier transitions but also raises new questions about the future of work itself. 
The Robotic Replacements – Factory and Warehouse Jobs:  The first wave of modern labor substitution
via robotics hit manufacturing, especially the auto industry . Starting in the 1970s and 1980s, car makers
introduced more and more robotic systems to handle dangerous or repetitive jobs: welding car frames,
spray-painting car bodies, and lifting heavy components. These industrial robots proved  extraordinarily
productive  – a welding robot could lay perfect seams around the clock, never tiring or getting distracted.
Over time, entire sections of assembly lines became automated, and the role of the human worker shifted
to maintenance, supervision, or the more dexterous tasks robots couldn’t yet do. Studies showed clear labor
impacts:  one  analysis  found  that  in  regions  of  the  U.S.  where  industrial  robots  were  adopted,
manufacturing employment fell and wages depressed relative to less automated regions . Each robot,
according to an Oxford Economics report, was estimated to  displace about 1.6 manufacturing jobs on
average】 . By one count, since 2000, automation (including robots) has contributed to the loss of
millions of factory jobs** in advanced economies . 50
51
52
18
Yet, it’s not a simple wipe-out. Even as robots replaced assembly-line welders or machine operators, new
roles for humans emerged:  robot technicians, programmers, quality control specialists . Factories still
employ people, but fewer in direct production and more in managing the automated systems. Warehousing
and logistics is another area:  automated guided vehicles  and robotic sorters now handle much of the
work in giant e-commerce fulfillment centers that used to require armies of pickers and packers. Amazon’s
warehouses, for example, use tens of thousands of small Kiva robots to move shelves to human workers,
reducing the walking labor and increasing efficiency – a partial automation that changed the nature of
warehouse  work.  Looking  ahead,  experiments  with  self-driving  trucks  and  delivery  drones  portend
further substitution in transportation and delivery sectors, potentially affecting truck drivers and couriers.
Though as of 2025 fully autonomous trucks are still in testing, the trajectory suggests that when (or if) they
become safer and cheaper than human drivers, that job too will face machine takeover .
AI Replacing White-Collar Tasks:  What distinguishes the current wave is the encroachment of automation
into  cognitive, white-collar jobs . Artificial intelligence – especially with the recent advances in machine
learning and so-called  generative AI  – is now capable of performing tasks once thought exclusive to
educated human workers. For example, AI systems can review legal documents and flag relevant clauses
(threatening to reduce the need for so many junior lawyers or paralegals in document review). They can
analyze medical images like X-rays or MRIs for signs of disease; one study famously found an AI as good as
radiologists at detecting certain cancers in scans. In finance, algorithms trade stocks and flag fraudulent
transactions, doing in microseconds what would take humans far longer . The “better, faster, cheaper”  test
often comes out in AI’s favor for these narrowly-defined tasks: an AI can be trained to be more accurate
(better) than a human in pattern recognition tasks like these, operate 24/7 at high speed (faster), and once
developed and scaled, handle each additional task at almost zero marginal cost (cheaper) – and often with
fewer mistakes (safer in terms of errors). 
We’ve also seen AI starting to handle customer service via  chatbots  and voice response systems. While
early versions were clunky (“Press 1 for …”) and often frustrating to customers, they have improved. Now, AI-
driven chatbots can answer a wide range of common inquiries, reducing the need for large call center
staffs. One can already see the effect: many companies maintain smaller human customer support teams
than a decade ago because first-line queries are handled by automated systems. In creative fields, AI is
beginning to make inroads as well – algorithms that can compose music, generate art, or write coherent
text (the latter exemplified by language models like GPT). This doesn’t mean the end of artists or writers –
but  it  does  mean  certain  laborious  or  routine  parts  of  their  work  can  be  automated.  For  instance,  a
marketing department might use AI to generate a rough draft of an ad copy, which a human then polishes,
thereby substituting away the initial creative grunt work.
Resistance and Concerns:  The rise of robotics and AI has prompted a mix of enthusiasm and anxiety, and
indeed resistance  in various forms. Labor unions in manufacturing have long been wary of automation. In
the 1970s, the United Auto Workers union negotiated provisions to slow the pace of automation and protect
workers – there’s a famous anecdote where UAW president Walter Reuther , shown a fully automated Ford
factory, quipped to the company executives, “ How are you going to get those robots to buy cars? ”  –
highlighting the broader economic concern that replacing workers could erode the consumer base . This
quote  captures  a  real  fear:  if  technology  displaces  too  many  jobs  too  quickly,  society  might  face
unemployment and inequality on a massive scale. Unions and workers have responded with demands for
retraining programs, job guarantees, or slower implementation. For example, in some cases, unions have
won agreements that new tech would not result in immediate layoffs but rather attrition over time. Still,
strikes and protests have occurred – from auto workers in the 1980s worried about “lights-out” factories, to53
54
19
more recent actions like the 2023 Hollywood writers’ strike, where one issue was limiting the use of AI in
script writing (writers fearing studios might use AI to draft scripts and cut writing staff). So there is active
resistance in white-collar realms too : journalists, writers, and even programmers express concern that AI
could encroach on their professions. 
On an institutional level, debates rage over  regulation of AI  – calls to ensure AI doesn’t run rampant in
displacing workers without societal preparations, or even suggestions like a tax on robots to fund social
safety nets. Governments are only beginning to grapple with these questions. Some countries facing aging
populations  (like  Japan)  have  eagerly  embraced  robots  to  fill  labor  shortages,  thus  encountering  less
resistance because the alternative is not replacing workers but compensating for a lack of workers. In other
contexts, especially where unemployment is high, resistance to job automation is naturally stronger . 
Timeline – Gradual then Sudden:  The timeline of robotics and AI substitution can be viewed in waves. The
first industrial robot in 1961 was a novelty; by the 1980s, thousands of robots were in factories, especially in
Japan which led the way in robot density. Still, up until the 2000s, most robots were limited to factory
settings doing fairly rigid tasks. The  2010s saw an acceleration : cheaper sensors, better AI, and the
pressure of global competition pushed more widespread adoption. The International Federation of Robotics
noted a record high of over half a million new industrial robots installed in 2021 alone , bringing the
global operational stock to about 3.5 million units . That number is on a steep upward curve. In other
words, robot adoption is now broad and accelerating . An Oxford Economics study in 2019 forecast that up
to 20 million manufacturing jobs globally could be lost to robots by 2030 , particularly affecting lower-
skilled regions more . Whether that exact number materializes, the trend is clear – more of the heavy
lifting and basic assembly in manufacturing will be automated. 
For AI, the timeline has its roots in mid-20th century computing, but practical impacts on jobs became
significant in the 21st century. By the 2010s, software algorithms had already replaced many clerical roles:
consider  how  spreadsheets  replaced  legions  of  bookkeepers  in  the  1980s,  or  how  online  databases
replaced file clerks and travel agents in the 1990s-2000s. Those were earlier waves of “office automation.”
The 2020s and beyond bring in the more sophisticated AI. Goldman Sachs in 2023 estimated that AI could
potentially replace or fundamentally change the equivalent of 300 million full-time jobs worldwide . That
doesn’t mean 300 million people unemployed – rather , that many jobs will have a substantial portion of
tasks automated. Historically, such estimates often overshoot in timing but not necessarily in scope; many
new tasks and jobs also emerge in the process. 
We are already seeing partial substitution : for example, AI medical diagnostic tools assist doctors (making
each doctor more effective, potentially reducing the number of specialists needed), AI coding assistants
help programmers write software faster (possibly meaning fewer junior programmers needed to achieve
the same output). Some companies are integrating AI in customer service so effectively that they might not
hire new agents even as they grow, relying on automated help. The timeline going forward might be
gradual  infiltration  rather  than  overnight  replacement  –  task  by  task  within  jobs  gets  automated.  A
lawyer’s job might not vanish, but perhaps the task of drafting a routine contract is 90% done by AI, so one
lawyer can handle the workload that used to require several, thereby reducing demand for lawyers over
time. Or in journalism, AI might handle basic financial reports or sports recaps, leaving human journalists to
focus on investigative pieces (but also meaning fewer total journalists employed). 
Better, Faster, Cheaper, Safer – The Evaluation:  In many of these new domains, safety  is a crucial factor
that can either hasten or delay substitution. For instance,  self-driving vehicles : the technology is very55
55
56
51
57
20
promising on cost and potentially on speed (trucks that drive day and night), but it will only be adopted en
masse when it’s proven  safer than human drivers . That’s a high bar and one reason fully autonomous
trucks haven’t taken over yet. In healthcare, an AI diagnostic tool must be extremely reliable (safe) for it to
be trusted without human oversight. So we see that while AI can potentially be “better” or “cheaper ,” if it’s
not yet safer or if its mistakes are of a kind we’re not comfortable with, humans remain in the loop. But the
moment an AI or robot clearly surpasses human safety records – for example, if self-driving cars one day
have, say, half the accident rate of human-driven cars – there will be  enormous economic and social
pressure  to adopt them widely (with the lives-saved argument in addition to cost savings). 
Robots have already improved safety in workplaces by taking on dangerous tasks. In chemical plants, robot
systems handle toxic substances; in mining, autonomous vehicles operate in hazardous areas, keeping
miners out of harm’s way. This “safer” aspect often wins over initial resistance from workers – few would
argue against removing a hazard, though they might hope that the worker displaced can move to a safer
role rather than be out of a job entirely. 
Residual Human Roles:  Despite the impressive strides, humans aren’t fully obsolete.  Maintenance and
oversight  of robots is a big category – robots need technicians to program and repair them. AI systems
require human input for training and fine-tuning (for now, at least). In many domains, a human touch or
judgment  is still valued: nurses and doctors for their empathy, teachers for the human connection, creative
directors for intuition and taste, etc. Often, the introduction of AI leads to a hybrid model: humans + AI
together outperform either alone. For instance, radiologists using AI diagnostic help catch more issues than
AI alone or human alone. So at least in the medium term, many jobs will be altered rather than eliminated –
a person’s role shifts to managing or complementing AI. 
There are also areas AI has struggled with: highly  unpredictable physical environments  are hard for
robots (thus construction workers and plumbers are not all replaced by robots yet, because every job site is
different and requires adaptability), and tasks requiring complex social interaction or creativity still often
need a person (AI can generate content, but genuine original art or deep scientific innovation is still largely
human-driven as of 2025, though AI aids the process). So residual jobs are likely to include niche skilled
trades , creative arts , leadership and interpersonal roles  – basically where human flexibility and empathy
are key. Additionally, completely new categories have popped up: who heard of a “robotics UX designer” or
“prompt  engineer”  a  decade  ago?  Now  these  are  emerging  roles  where  humans  craft  how  AI  and
automation interact with us. 
Unique  Aspects  of  the  Modern  Transition:  One  unique  factor  now  is  the  scale  and  speed .  Past
substitutions often unfolded over generations, giving labor markets time to adjust. The feeling today is that
AI might disrupt multiple industries within just a decade or two – a pace that could outstrip the ability of
some workers to retrain or shift. This raises concerns about societal preparedness. It also brings up the old
question: will new jobs appear to absorb those displaced? Historically, yes – new industries have always
emerged.  The  optimistic  view  is  that  freeing  humans  from  rote  tasks  will  unleash  creativity  and  new
industries  (just  as  industrialization  eventually  created  whole  new  sectors  like  telecommunications,
computing, etc.). The cautious view is that even if new jobs come, there may be a painful transition period
and the new jobs might require very different skills. For example, AI may boost demand in fields we can’t
imagine yet – maybe climate engineering or space industries – but the factory worker or call center rep
losing their job today might not smoothly move into those roles without significant retraining and support. 
21
What’s clear is that the “better , faster , cheaper , safer” framework remains a solid predictor:  when AI or
robots decisively surpass humans in a task, that task will be automated . We’ve seen it in chess and
other games (where AIs dominate), in logistics routing, in translation (machine translation is now often
good enough for many uses, reducing need for human translators in basic scenarios), and it’s looming in
things like driving when the tech matures. It’s notable that, unlike early industrial machines which replaced
muscle, AI can replicate certain cognitive skills. That broadens the horizon of substitution to essentially any
work that is routine or pattern-based, even if “mental.” 
Another unique element is that robots and AI could potentially scale without the diminishing returns that
human labor has. A human working more hours gets tired and makes mistakes; a server farm running AI
can scale up almost indefinitely with more computing power , potentially creating unprecedented output
with very few people involved. That suggests a possible future economic scenario where productivity soars
but traditional employment doesn’t rise in tandem – raising questions about distribution of wealth (who
owns the machines?) and the need for new social contracts (like universal basic income, a hotly debated
idea born from the notion of tech-driven job scarcity). This is speculative but actively discussed in economic
circles . 
In essence, the robotics and AI chapter of labor substitution is still unfolding. We are living through it. It has
many  parallels  with  past  shifts  –  fears,  resistance,  eventual  acceptance,  and  adaptation  –  but  also
differences of degree. As we conclude our historical journey, synthesizing these lessons, we will reflect on
how consistently the pattern of “better , faster , cheaper , safer” has driven change, and under what conditions
these changes have been smooth or rocky. The hope is that by understanding the past, we can navigate the
present and future of labor substitution with wisdom, mitigating the pains and maximizing the gains of our
ever-advancing machines.
Chapter 7: Conclusion – The “Better, Faster, Cheaper, Safer”
Imperative Across History
From the printing press to the AI algorithm, we have followed a recurring narrative: whenever technology
clearly  demonstrates  that  it  can  do  a  job  better,  faster,  cheaper,  and  safer  than  human  labor ,  the
replacement of that labor becomes only a matter of time. This through-line connects a 15th-century scribe
watching Gutenberg’s movable type render his copyist skills obsolete, to a 20th-century factory worker
seeing robots encroach on the assembly line, to a 21st-century office worker training an AI that might
eventually take over routine parts of her job. The consistency of this pattern across vastly different eras and
industries is striking. In each case, the initial introduction of a machine offers some advantages but also has
limitations; there is often a period of coexistence and resistance. But as the technology matures and proves
its superiority on key metrics, adoption becomes economically  inevitable  for those who wish to remain
competitive. 
Universality of the Drivers:  The four benchmarks – better (quality), faster (speed/productivity), cheaper
(cost efficiency), safer (risk reduction) – have shown up time and again as the rationale for substituting
machines for people. Not every technology scores on all four at first, but achieving a decisive edge in most
of them seems sufficient to tip the scales. For instance, the automatic telephone exchange wasn’t better  in
service  quality  initially  (customers  missed  the  personal  touch),  but  it  was  ultimately  much  faster  and
cheaper , and eventually reliable enough that the quality became on par (and arguably better since fewer
errors). The printing press was not necessarily safer  (scribe work wasn’t unsafe to begin with), but it was58
22
indisputably faster and cheaper per book, and that alone drove its spread. Tractors had to become not just
faster than horses, but also easier (safer) to operate and maintain, and cheaper in the long run – which they
did, sealing the fate of animal-powered farming . In modern times, an AI system might need to prove it’s
not only faster and cheaper but also  accurate and safe  (particularly for tasks like driving or medical
diagnostics) to fully displace humans. Once it does, the economic logic kicks in forcefully. 
Businesses and societies that adopt the superior technology gain a competitive advantage – higher output,
lower  costs,  improved  safety  outcomes  –  and  those  that  don’t  risk  falling  behind.  History  shows  that
attempts to hold back the tide, when the machine is truly superior, tend to fail in the long run . The
Ottoman  Empire’s  long  ban  on  printing,  for  example,  arguably  left  it  lagging  in  enlightenment  and
education . The tailors who smashed Thimonnier’s sewing machines in 1830 could not stop the eventual
flood of Singer machines and the ensuing boom in ready-made apparel . Their violent resistance only
delayed their adjustment. This is not to say resistance is futile on all fronts – but when it relies purely on
suppression rather than addressing underlying economics, it seldom succeeds indefinitely. 
Conditions for Smooth vs. Disruptive Transitions:  The historical cases also teach us about conditions that
make labor substitution more likely to be smooth or, conversely, particularly disruptive . One condition
is the pace of change . When substitution unfolds gradually, there is more time for workers to retrain or
retire  and  for  new  generations  to  steer  career  choices  elsewhere.  For  example,  over  many  decades
agriculture shed labor; younger people increasingly chose non-farm jobs, softening the blow (though it was
still plenty disruptive, especially in mid-century rural areas). In contrast, if AI were to displace a large chunk
of jobs in a single decade, it could outpace our ability to adapt, leading to sharper unemployment spikes or
social strain. 
Another condition is complementary innovation and job creation . In many historical cases, even as one
category of jobs declined, entirely new industries and roles emerged – printers and booksellers in place of
scribes, factory maintenance crews in place of some assembly workers, IT professionals in place of typists,
and  so  on.  The  classic  economic  argument  (often  attributed  to  Schumpeter)  is  that  this  “creative
destruction” leads to higher productivity and new wealth, eventually creating more  jobs than were lost
. Indeed, societies that embraced technology tended to grow richer and could then afford to employ
people in services and creative pursuits that previously didn’t exist. However , the distribution  of those gains
matters. When the benefits of higher productivity are widely shared – via rising wages, shorter working
hours, or new public goods – the transition feels like progress. When they are concentrated (e.g., early
industrial factory owners reaped profits while workers toiled for low pay), the transition feels exploitative
until social adjustments (like labor rights and social safety nets) catch up . 
We also saw that  public policy and institutions  can ease or impede transitions. Education systems that
prepare the next generation with skills suited for new technologies help smooth things out – for instance,
widespread typing and clerical training in the early 20th century helped millions of women move into office
jobs, supplying the labor needed for the expanding service sector as machines took over manufacturing
and agriculture. Conversely, lack of retraining opportunities can leave displaced workers stranded. Social
policies like unemployment insurance or UBI (universal basic income) weren’t topics in 1800, but today
they’re part of the conversation on how to handle rapid AI-driven shifts. 
Psychological  and  Social  Factors:  Each  wave  of  substitution  not  only  had  economic  logic  but  also
emotional impact . People derive meaning and identity from work, and seeing a machine do what you
prided yourself on can be demoralizing. The monks who illuminated manuscripts viewed the printing press15
14
47
59
60
61
23
with spiritual dread (printing the holy word by machine seemed almost sacrilegious to some early on).
Skilled artisans in textiles felt a loss of craftsmanship when power looms churned out bulk fabric. Telephone
operators, many of whom saw their job as providing quality customer service, felt understandably devalued
when told a machine could do it faster . Understanding this human side is crucial; it’s why sometimes
nostalgia or niche markets  preserve old ways beyond their economic prime. We saw that with artisanal
printing, bespoke tailoring, analog photography (where digital cameras took over , but film still has an
enthusiast market) – there’s often a residual appreciation for the human touch, even if it’s no longer
mainstream. These niches usually don’t employ large numbers, but they serve as cultural touchstones that
not everything of the past is lost. 
When is Substitution Inevitable?  The historical record suggests a few conditions that make substitution
most likely to be rapid and inevitable:
When the machine’s advantage is overwhelming and visible.  If a machine is not just a bit better
but  order-of-magnitude  better  (like  the  printing  press  multiplying  output  hugely  or  AI  solving
problems humans couldn’t), adoption tends to be swift. Firms that don’t adopt simply can’t compete
on cost or output and either adapt or perish. This was seen with the power loom vs. hand weavers –
once the loom got efficient, hand weaving for mass market was done for , aside from luxury craft. We
may see something similar if, say, autonomous vehicles become drastically safer and cheaper – who
would insure human drivers if AIs are significantly less accident-prone? 
When labor is a large portion of cost and the new tech can slash it.  Mechanized agriculture took
off especially when labor became relatively scarce or expensive (e.g., post-WWII, farm wages rose,
making tractors even more attractive ). In modern times, industries facing labor shortages or
high wage pressure are most primed for automation. Japan’s adoption of robots is partly due to an
aging population and fewer young workers – it’s adopt robots or shrink output. On the flip side, if
labor is very cheap, there’s less incentive to automate – that’s why some labor-rich developing
countries  still  have  more  manual  processes;  the  cost  equation  differs.  Over  time,  as  tech  gets
cheaper and more capable, it reaches even those contexts.
When supportive infrastructure exists.  Some technologies need a whole ecosystem (electricity for
factories and offices to run machines, internet connectivity for digital tools, etc.). The telephone
automation waited until reliable electricity and network standardization were in place. AI today
benefits from cloud computing and global internet – without those, its impact would be far smaller .
So inevitability often aligns with the maturation of complementary systems.
When societal/regulatory barriers are low.  The more open a society/economy is to change (or the
more desperate it is for improvement), the faster substitution happens. The Ottoman printing press
ban was a regulatory barrier; once lifted, printing presses entered quickly. In contrast, today, if
regulators slow approval of self-driving cars due to safety concerns, that can delay substitution even
if the tech is ready. Eventually, though, if evidence piles up that it’s better , regulation tends to adjust
(perhaps with new safety standards, etc.). 
When  capital  is  available.  Replacing  labor  with  machines  often  requires  upfront  investment.
Periods of robust capital markets or government incentives see faster automation. For example,
factories heavily automated when interest rates were low and financing equipment was easier , or
when governments offered tax breaks for new machinery.• 
• 
18
• 
• 
• 
24
Inevitability vs. Choice:  It’s worth concluding on an important nuance: while economics makes certain
changes compelling , human choices and values do shape how we implement them. It was not written in
stone that telephone operators had to vanish as quickly as possible – Bell System chose to retain them
longer for service reasons . And now, we collectively face choices with AI: to what extent do we want
AI replacing roles like teachers, doctors, or judges? We might decide that even if an AI could do X, we prefer
humans in some roles for ethical or quality reasons. For instance, there’s ongoing debate over autonomous
weapons – just because a military AI could make decisions faster doesn’t mean we’re comfortable removing
human judgment from life-and-death decisions. So, substitution is most inevitable in tasks that are clearly
defined and where outcomes are measurable  (productivity, cost, safety stats). In more nuanced human
arenas, we might apply brakes or insist on a human in the loop, even if the machine is in theory “better” on
some metrics, because our definition of “better” includes intangible human elements. The framework still
applies, but how we weight those four factors can be culturally or politically influenced.
A Synthesis of Hope and Caution:  Looking back, each major substitution ultimately freed humans from
monotonous or back-breaking work and coincided with greater prosperity and new opportunities. Literacy
spread  after  the  printing  press,  diets  improved  and  people  pursued  other  vocations  after  farm
mechanization reduced food costs, offices became more efficient and spawned new professions with the
advent of typewriters and computers. Productivity growth, largely driven by technological substitution of
labor , is the cornerstone of rising living standards . However , the journey was often rocky for those
caught in transition. Many a hand weaver , switchboard operator , or copy clerk lived through the painful
redundancy of their skills. Societies that navigated these transitions best invested in education, enacted
protections for workers (so the gains of tech were shared), and maintained a culture that encouraged
adaptation. 
The consistent lesson is that while you  cannot halt progress  when a machine is truly superior , you  can
channel it: cushion the impacts, retrain and redeploy workers, and ensure the wealth created benefits the
many and not just the few . In the long run, new jobs and industries have always arisen – often jobs
focusing on what is uniquely human: creativity, interpersonal relations, complex problem-solving, and so
on. As AI encroaches, humans may gravitate even more to those areas. And who knows – the pattern might
continue with humans finding higher pursuits once freed from routine labor . John Maynard Keynes once
envisioned that by 2030, automation might allow much shorter workweeks and more leisure – essentially,
machines doing most of the work, with humans enjoying the fruits. That hasn’t fully happened yet (people
still generally work 40-hour weeks, though far fewer on farms or factory lines than a century ago). The
distribution of gains and our social choices have a lot to do with it.
In sum, history affirms the “better , faster , cheaper , safer” dictum as a powerful driver of economic change.
When conditions align, labor substitution by machines becomes a tide that, as the saying goes, “ raises
productivity while drenching those unprepared .” Our challenge and opportunity, as we stand amid
perhaps the fastest wave yet, is to be prepared – to ride the wave by evolving our skills and systems, rather
than being swept away. The past shows that if we manage it wisely, technological substitution not only
increases efficiency but can also  enrich human life  – not just materially, but by allowing us to pursue
endeavors beyond the grunt work we have consigned to our machines. 
Sources:  The historical milestones and analyses in these chapters are drawn from a range of reputable
sources: economic histories, scholarly articles, and data from institutions. Notably, they include examples
like the Ottoman printing ban on pain of death , statistics on agricultural labor decline , accounts of
telephone automation delaying for decades despite proven technology , studies on industrial robot2562
6360
61
2 15
2625
25
impact , and contemporary analyses on AI’s potential job effects . These references, among others
throughout the text, support the narrative that whenever technology has surpassed human labor on key
metrics, substitution has followed, albeit with timing and nuances shaped by social context. Each chapter’s
events reinforce the overarching thesis, painting a continuous story of human work constantly reshaped by
our ingenious – if sometimes disruptive – tools. 
Printing press - Wikipedia
https://en.wikipedia.org/wiki/Printing_press
Global spread of the printing press - Wikipedia
https://en.wikipedia.org/wiki/Global_spread_of_the_printing_press
3 Stop the Presses: Printing the Koran - Oxford Academic
https://academic.oup.com/book/25649/chapter/193076320
Age of Invention: Why Didn't the Ottomans Print More?
https://www.ageofinvention.xyz/p/age-of-invention-why-didnt-the-ottomans
What the printing press and stagnation in the Islamic world teach ...
https://fasterplease.substack.com/p/what-the-printing-press-and-stagnation
Industrialization of Agriculture | Food System Primer
https://foodsystemprimer .org/production/industrialization-of-agriculture
When the automobile was the world's technological savior
https://automedia.revsinstitute.org/been-there-done-that-when-the-automobile-was-the-worlds-technological-savior
Economic History of Tractors in the United States – EH.net
https://eh.net/encyclopedia/economic-history-of-tractors-in-the-united-states/
Goodbye, Operator | Richmond Fed
https://www.richmondfed.org/publications/research/econ_focus/2019/q4/economic_history
Telephone switchboard - Wikipedia
https://en.wikipedia.org/wiki/Telephone_switchboard
Technology and Foreign Affairs: The Case of the Typewriter | American Diplomacy Est
1996
https://americandiplomacy.web.unc.edu/1997/12/technology-and-foreign-affairs-the-case-of-the-typewriter/
HAD :: A Machine for Writing: A Brief History of the Typewriter
https://www.havehashad.com/web_features/a-machine-for-writing-a-brief-history-of-the-typewriter
The arrival of women in the office - BBC News
https://www.bbc.com/news/magazine-23432653
Sewing Machine | Encyclopedia.com
https://www.encyclopedia.com/science-and-technology/technology/technology-terms-and-concepts/sewing-machine
The uneven labor market impact of industrial robots
https://www.aeaweb.org/research/automation-employment-gaps-us
Robots 'to replace up to 20 million factory jobs' by 2030
https://www.bbc.com/news/business-4876079951 57
1
2 512
3 4
6 7 8 910 11 13
14
15 19 20
16
17
18 22 23 24 25 26 27 28 29 62
21 30 31 32
33 34 35 39 40 45
36 37 38 41 43 44
42
46 47 48 49
50
51 56
26
55+ NEW Robotics Industry Statistics + Market Growth (2025) - Genius
https://joingenius.com/statistics/robotics-industry-statistics/
Dialogue Origin: “How Will You Get Robots to Pay Union Dues?” “How Will You Get Robots to Buy
Cars?” – Quote Investigator®
https://quoteinvestigator .com/2011/11/16/robots-buy-cars/
World Robotics Report: “All-Time High” with Half a Million Robots Installed in one Year - International
Federation of Robotics
https://ifr .org/ifr-press-releases/news/wr-report-all-time-high-with-half-a-million-robots-installed
AI could replace equivalent of 300 million jobs - report - BBC News
https://www.bbc.co.uk/news/technology-65102150
Walter Reuther | - | … speaking, because it is allowed.
https://notebookm.com/tag/walter-reuther/
Creative Destruction - Econlib
https://www.econlib.org/library/Enc/CreativeDestruction.html52
53 54
55
57
58
59 60 61 63
27