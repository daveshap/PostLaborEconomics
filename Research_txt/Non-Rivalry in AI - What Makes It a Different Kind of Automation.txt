Non-Rivalry in AI: What Makes It a Different Kind of Automation In a recent conversation about “post-labor economics,” a colleague insisted that artificial intelligence (AI) is simply the next wave of automation – akin to past innovations like industrial machinery or office computers – and should be treated as such by economists. This is a common misconception. AI differs from earlier automation in fundamental ways that have profound economic implications. It is not just a more powerful tool; it is a general-purpose technology with non-rival, intangible capital characteristics, and its primary constraints are shifting from human labor to energy and computing resources . This report builds on that discussion to dispel misunderstandings and examine AI through an economics lens – covering its non-rivalry, general-purpose nature, impacts on productivity (TFP), the “economic agency” paradox, price signals under near-zero marginal costs, energy constraints, Baumol’s cost disease, and the emergence of “statutory jobs.” The goal is an exhaustive, up-to-date analysis of how AI represents a different kind of automation and what downstream consequences economists and policymakers must consider . AI as a General-Purpose Technology (Not Just “Another Automation”) Artificial Intelligence is widely recognized as a General-Purpose Technology (GPT) – meaning it has broad applicability across the economy and can spur complementary innovations, much like electricity or the internet did . Past waves of automation were often narrow: for example, mechanized looms revolutionized textiles, and spreadsheet software automated bookkeeping. AI, by contrast, is general : its machine learning algorithms and models can potentially perform any information-based task, given enough data and training. As one economic analysis put it, “the more important economic effects of AI… stem from the fact that [it] embod[ies] the characteristics of general purpose technologies” . In practical terms, this means AI’s impact is not confined to one industry or skill level – it can affect manufacturing, services, creative work, scientific research, and beyond. Because AI is a GPT, its adoption can lead to economy-wide transformations over time. We saw this pattern with earlier GPTs: electricity required factories to reorganize around new power sources, and computers needed complementary investments (software, skills, processes) before productivity surged. Similarly, fully reaping AI’s benefits may require reorganizing workflows, retraining workers, and developing new business models. This lag contributes to the modern “productivity paradox” of AI: despite rapid advancements, aggregate productivity statistics have not yet soared, likely due to adjustment frictions and measurement lags . History suggests that as AI diffuses and complements are put in place, its contribution will grow. In fact, AI is already beginning to boost productivity in specific applications – for example, field studies found that customer service workers assisted by generative AI were ~14% more productive . Looking ahead, experts project that AI could raise annual labor productivity growth by about 0.25 to 0.9 percentage points in the coming decade (in the United States), depending on how broadly it is adopted . These figures are significant at a macro level, potentially jumpstarting the stagnating total factor productivity (TFP) growth of recent years.1 1 23 4 5 1 One feature that sets AI apart from earlier automation is its ability to perform non-routine and cognitive tasks , even at high skill levels. Historically, automation and information technology mainly displaced routine, manual, or repetitive work. AI, however , is encroaching on white-collar and professional domains once thought safe – writing and reviewing legal documents, coding software, diagnosing medical images, creating graphic art, etc. The IMF notes that “one of the things that sets AI apart is its ability to impact high-skilled jobs” , not just routine or low-skill jobs . In advanced economies, up to 60% of jobs could be influenced by AI, and notably even half of high-skill jobs may see key tasks executed by AI, reducing demand for those workers . This breadth of impact is unlike past automation waves (which often mostly affected, say, manufacturing labor). AI can substitute and complement human labor across the board – augmenting some roles with higher productivity, while outright replacing specific tasks in others. Such wide reach reinforces AI’s general-purpose character and implies far-reaching economic adjustments. In summary, economists should approach AI not as a narrow labor-saving device, but as a foundational technology with economy-wide reach. Its deployment will likely mirror other GPTs: slow at first, then transformative. Crucially, however , AI’s digital and non-physical nature makes its economic behavior differ from the machines of the past, as the next sections explore. AI as Non-Rival Intangible Capital: Infinite Use, New Constraints One of the most economically significant differences of AI is that it operates as an intangible, non-rival form of capital – essentially a form of software or codified knowledge. Non-rivalry means that one entity’s use of a good does not diminish the ability of others to use it. A classic example is a piece of software or a digital design: once created, it can be copied or deployed repeatedly at very low marginal cost. AI models and data are similarly non-rival : if one firm uses a trained AI algorithm, it doesn’t prevent another firm from using the same algorithm (as long as they have access) . This is fundamentally different from traditional capital like machines or vehicles (which are rivalrous , since one factory’s robot arm cannot be simultaneously used in another factory). As researchers note, “in contrast to [traditional] labor and capital… AI [is] a non-rival good that can be simultaneously used by multiple firms” . In principle, a single AI model (or its software code) can be deployed across an unlimited number of tasks and locations at once – a dramatic scalability that physical tools lack. However , while the software or model is non-rival, its usage often requires complementary rival inputs : computing power , specialized chips (GPUs/TPUs), electricity, and data storage. These are physical resources and are rivalrous (a GPU can only execute one workload at a time; a kilowatt-hour of electricity cannot be reused once consumed). Thus, the primary scarcity in AI-driven production shifts to these areas – GPU hours and energy – rather than human labor per se. In effect, AI transforms certain forms of work into problems of computing and power supply. We will discuss energy constraints shortly, but it’s important to recognize that the economics of AI-heavy production more closely resemble the economics of software (high fixed cost to develop, very low marginal cost to run) than the economics of manufacturing a physical good. The rise of AI is part of a broader economic trend: the growing importance of intangible capital. Over the past two decades, firms have been investing heavily in intellectual property, software, data, R&D, and other intangibles – often outpacing investment in tangible assets like machines or buildings. In fact, investment in intangible assets has been growing three times faster than investment in physical assets in recent years . In 2024, across 27 major economies, intangible investment (in software, databases, R&D, branding, etc.) grew ~3% to reach $7.6 trillion, even as tangible investment stagnated . This reflects a “fundamental shift in how economies grow and compete” . Software and databases have6 7 89 10 11 12 13 2 been the fastest-growing categories of intangibles (over 7% annual growth in the 2010s) , a trend likely amplified by the AI boom , which increases demand for data, training datasets, and algorithms . AI thus sits at the apex of the intangible economy: its core inputs and outputs (models, code, data) are non- physical. The non-rival, intangible nature of AI has several key implications: High Fixed Costs, Low Marginal Costs: Developing a state-of-the-art AI system (like a large language model) requires substantial upfront investment – hiring talent, computing for training runs, data collection – but once built, the cost to deploy it for an additional user or task is relatively tiny (mainly electricity and server time). This cost structure can lead to increasing returns to scale and potentially winner-takes-most markets. For instance, if one company spends the huge fixed cost to create a top-tier AI, it can then serve millions of customers at a low cost each, undercutting competitors who might find it unprofitable to invest in a rival system. This helps explain why we see increased market concentration and pricing power in digital and AI-intensive industries . Empirical studies have found that markups (price over cost) tend to be higher in industries with greater software and AI intensity, reflecting leading firms’ ability to leverage intangibles and scale with low marginal cost . Non-rivalry thus can fuel monopolistic outcomes unless checked – a few platforms or providers might dominate AI services globally, enjoying large profits by virtue of their initial intangible investments. Non-Rivalry and Optimal Diffusion: From a social welfare perspective, non-rival goods have the attractive property that once created, the efficient price for use is zero (or very low) , because using it more doesn’t use it up. In a frictionless world, we would want AI knowledge to be disseminated widely at near-zero cost to maximize productivity. However , doing so runs into the classic problem of intangible goods: if they are freely available, the creators might not recoup their large development costs, stifling incentives to innovate. This is why AI algorithms, while non-rival, are often made excludable – through intellectual property rights, trade secrets, or cloud-based deployment – so that firms can charge for access . Society faces a trade-off between broad access (to boost aggregate productivity) and providing rewards for innovation. We see this tension in today’s AI landscape: some models are proprietary (accessible only via paid APIs or services), while others are open-sourced to spur widespread use. Economists are watching how this plays out, as it will influence productivity and competition dynamics. Policy may need to encourage wider diffusion of AI (through open research or subsidies) while preventing excessive monopoly power from intangible assets. Intangible Capital and Measured Productivity: Intangibles like AI can also confound traditional economic measurement. Investing in intangible capital doesn’t always show up in GDP the same way building a factory does (some intangible investments are expensed as operational costs, and the output of free digital services isn’t fully captured). There is concern that our productivity metrics and GDP accounting understate the gains from digital technologies – for example, if AI drastically lowers the cost of certain services (like translation or information retrieval) and many are offered free or bundled, the value delivered to consumers (consumer surplus) may not be reflected in market prices or output statistics. This complicates analyses of TFP and growth in the AI era . Researchers are working to adjust productivity measures to include intangible contributions , but it remains challenging.14 15 • 16 17 16 • 18 • 2 19 3 In short, AI as an intangible, non-rival capital is a double-edged sword. It offers the possibility of near- limitless, low-cost replication of “digital labor ,” breaking the traditional link between labor hours and output – but it also raises new issues around incentivizing innovation, market power , and economic measurement. It urges economists to rethink models that assumed rival inputs – AI is more like a new knowledge factor that behaves unlike land, labor , or traditional capital. Crucially, because AI’s use hinges on physical computation, this “infinite supply” of AI labor is ultimately constrained by something very concrete: energy . The Energy Constraint: From Labor-Limited to Power-Limited Production Although the algorithms are intangible, AI systems in practice are power-hungry , demanding vast amounts of electricity and specialized hardware. As we replace human labor with computation, the bottleneck shifts to energy. One vivid illustration: training GPT-3 (a large language model) just once consumed about 1,287 MWh of electricity – as much power as an average U.S. home would use in 120 years . And that is for a single training run; large AI firms now train many models and run thousands of queries per second in production. The global energy footprint of AI is already significant and rising quickly . In 2023, data centers (driven increasingly by AI workloads) consumed roughly 500 terawatt-hours of electricity – about as much as an entire country like France or Germany consumes in a year . By 2030, data center consumption could triple to 1,500 TWh , according to projections, which would make it comparable to India’s current total electricity usage . This surge is directly linked to AI proliferation: more servers, more cooling systems, and more computations per product or service. If these projections hold, AI data centers might draw 1.5 times as much power as the entire global fleet of electric vehicles by 2030 . In the United States alone, power demand from large-scale computing centers could more than triple by 2030, exceeding 600 TWh annually (in a mid-range scenario) . The shift to an AI-centric economy thus has parallels to the industrial revolution’s energy revolution: just as the 19th century saw energy consumption boom with mechanization (coal and steam powering factories), the 21st century may see a new electricity boom to power intelligent machines. This raises several economic considerations: Energy Supply and Price Signals: The need for abundant electricity becomes a central economic constraint. If power supply expands smoothly to meet AI-driven demand, electricity prices may remain stable, and AI usage can grow without much friction. However , if supply lags behind demand, we could see soaring energy prices that act as a brake on AI adoption . The IMF warns that an unresponsive energy sector could lead to steep power cost increases “that hurt consumers and businesses and possibly curb growth of the AI industry itself” . In essence, energy could become to the AI economy what labor was to the industrial economy: a key input that determines scalability and cost . Policymakers will need to encourage investments in power generation (especially sustainable sources) and grid infrastructure to ensure AI’s growth isn’t stalled by energy shortages or price spikes . There’s also a geopolitical angle – regions with cheaper electricity might attract more data centers and AI labs, potentially shifting some economic centers of gravity based on energy availability. Environmental Impact: The energy hunger of AI has environmental externalities, particularly if the additional electricity comes from fossil fuels. The estimated growth in data center usage would add20 21 21 22 23 • 24 24 2425 • 4 on the order of 1.7 gigatons of CO₂ emissions from 2025 to 2030 (under current energy mixes) – roughly equivalent to adding the five-year emissions of a country like Italy . That is a non- trivial increase in global emissions, complicating efforts to combat climate change. This externality is not traditionally factored into the private cost of deploying AI, so without policy intervention (like carbon pricing or strong shifts to renewables), the market may over-consume computational power from a climate perspective. Fortunately, there is also positive news: AI can be made more efficient, and a lot of research is going into reducing power per computation (for instance, new chip designs, optimized algorithms, and smarter data center cooling). Some AI models (including open-source ones) are designed to be more computationally efficient . But there’s a rebound effect: making AI cheaper and more efficient can lead to more usage (“Jevons’ paradox”), so total energy demand might still rise . Navigating this will require balancing innovation in efficiency with policies to manage total consumption and emissions – for example, ensuring AI clouds run on renewable energy and that efficiency gains are not offset by runaway deployment. Energy as the Marginal Cost of AI Services: Because AI’s marginal costs are mostly the electricity and hardware wear-and-tear , energy effectively sets a floor for the cost of AI outputs . For instance, if it takes X joules and Y seconds of GPU time to produce an AI result, the provider will price services to at least cover that. If renewable energy becomes extremely cheap, AI services could become correspondingly cheaper . Conversely, an energy crunch would make AI usage more expensive. In economic terms, the price signals in an AI-rich economy may start to heavily reflect energy scarcity rather than labor scarcity . Today’s energy prices already factor into the costs of cloud computing time. In the future, one could imagine pricing models where tasks are scheduled based on real-time electricity prices (e.g. non-urgent AI jobs run when power is cheap or plentiful). Indeed, experimental software frameworks can optimize when to run AI training jobs to take advantage of low-carbon, off-peak power . This intertwining of AI with energy markets is something economists and operations researchers are increasingly examining. In summary, while AI decouples production from human labor to an extent, it recouples it to energy. We are moving from a labor-constrained model to an energy-constrained model of automation. This shift underscores that AI-driven abundance is not free – it requires robust energy infrastructure. It also highlights a potential new limiting factor for growth: where once the number of workers or their productivity capped output, now it could be the available terawatt-hours and computational throughput that determine how much AI-enabled output can be produced. In an AI economy, “solve for energy” becomes as crucial as “solve for labor productivity” was in the past. Price Signals, Costs, and Market Dynamics in an AI-Abundant Economy The advent of near-zero marginal cost for many AI-driven services challenges traditional market dynamics and price signaling. In classical economics, prices are supposed to reflect relative scarcity and marginal cost. But what happens when the marginal cost of certain outputs is effectively zero (aside from a bit of electricity)? AI has already given us a taste: consider digital goods like music or news articles – once digitized, the cost to serve one more user is almost nothing, leading some providers to either give them away (relying on ad revenue or data harvesting) or bundle them in subscriptions. AI extends this “zero marginal cost” phenomenon to many tasks that used to be labor-intensive and thus costly.26 27 27 • 28 5 For example, writing a piece of marketing copy or translating a document used to carry a price reflective of a human’s time and skill; with modern AI, the cost is primarily the computing time (pennies or less), which means the supply price could plummet. If competition in these services is high (including open-source AI alternatives), we may see prices for certain cognitive services driven down drastically – a boon for consumers and businesses that use those services, but a direct income loss for workers who formerly earned wages doing them. This is part of the mechanism behind expected wage pressure in exposed professions. Indeed, the labor market “price” (wage) for easily-automated tasks is likely to decline as AI becomes a close substitute. We already observe some of this: content writers, translators, basic graphic designers, and others face downward fee pressure because clients know AI can do a passable job cheaply. These price signals – lower wages, lower service prices – indicate the reduced scarcity of those skills in the market. In classical terms, the supply curve shifted massively to the right. However , not all markets will perfectly competitive or transparent in the AI era. If a few companies own the best AI models (protected by IP and heavy infrastructure), they may act as price-setters rather than price-takers. In such cases, we might not see near-zero prices even if costs are near-zero; instead, firms might charge what the market will bear , reaping large profits. For instance, if one company’s AI is significantly better at drug discovery than others, it can license that capability at high prices, despite the low marginal cost of running another simulation. This raises antitrust and regulatory questions: ensuring that AI’s benefits (low costs) flow through to consumers broadly, rather than being bottled up by monopolies. It also relates to intellectual property regimes – if patents or copyrights on AI outputs are too strong, they might artificially keep prices high and limit the non-rival benefit. On the other hand, weak IP could discourage the huge investments needed to develop cutting-edge AI. Achieving the right balance is tricky and will likely evolve via policy debates and market feedback. Another area where price signals may misfire is in public goods and externalities . If AI makes it extremely cheap to generate, say, disinformation or spam, the private “price” of doing so is low, but the social cost could be high – calling for regulatory intervention since the market won’t naturally price that harm. Conversely, AI could produce positive externalities (like open research discoveries) that are underprovided if left purely to private incentives. Economically, there is a case for government or philanthropic support for open AI models and data as public goods , to fully realize the non-rival nature for society’s benefit. Finally, we must consider price signals in the presence of energy constraints , as discussed. Energy prices may become a barometer for AI activity. If electricity prices spike, AI usage might temporarily retreat (similar to how high oil prices can dampen transportation or manufacturing). We might see new kinds of demand response: for example, companies scheduling AI-heavy processes in off-peak hours when power (and thus computing) is cheaper , effectively making AI workload an elastic demand linked to energy markets . Market pricing for cloud compute may even vary in real-time with energy costs in data center locations. These linkages mean that energy policy (like carbon taxes or subsidies for renewables) could indirectly influence the cost of AI services and the pace of AI adoption. In summary, AI pushes us toward an era of abundance in many domains – but it’s a conditioned abundance. The marginal cost of knowledge work tends toward zero, yet the institutions of markets (pricing, competition) and the constraints of the physical world (energy, hardware) will determine how that abundance is allocated and priced. Economists anticipate deflationary effects in some sectors due to AI (cheaper digital services), while possibly inflationary pressure in inputs like energy or high-end hardware. Traditional price signals may need supplementation: for instance, if AI-driven deflation causes unemployment or inequality, simply letting the market lie may not be optimal – policy might step in with28 6 wage insurance, retraining, or redistributive measures (because the price mechanism by itself won’t re- employ displaced workers if their labor is truly obsolete at any price above zero). In essence, AI challenges us to refine how markets function when one of the fundamental factors of production (intelligence/labor) becomes artificially super-abundant and cheap . Distributional Impact and the Economic Agency Paradox A major downstream consequence of AI’s rise is its effect on income distribution and the role of labor in the economy . If AI indeed allows machines to perform a significant share of productive work, we face the prospect of a declining labor share of income and a greater share of output accruing to owners of capital (the AI systems and the infrastructure). This has been a concern with automation for decades, but AI’s broad capabilities intensify it. The IMF’s analysis warns that AI is likely to worsen overall inequality in most scenarios . There are several mechanisms behind this: Labor Displacement and Wage Polarization: As AI substitutes for human workers in various tasks, the demand for certain skills will fall. Workers who cannot be re-skilled to complementary roles may see their wages drop or their jobs eliminated entirely. At the same time, workers who can work with AI (or in fields that AI can’t do well yet) might become more productive and more highly rewarded. This creates polarization – some see gains, others losses . For example, a savvy data analyst who leverages AI tools might handle 10x the work and command higher pay, whereas a routine office clerk might be laid off because an AI system now handles scheduling and paperwork. The IMF finds that “workers who can harness AI [will see] an increase in their productivity and wages—and those who cannot [will] fall behind” . Younger , digitally native workers might adapt more easily, whereas older workers could struggle, exacerbating generational divides . Capital Owners Gaining a Larger Share: The productivity gains from AI adoption will, at least initially, flow primarily to the companies and individuals who deploy the AI – which generally means shareholders and tech proprietors, not the frontline workers. If a factory replaces 100 workers with an AI-driven robotic system, the wages saved translate into either higher profits for the firm or lower prices for consumers (or some combination). In practice, evidence suggests profit share tends to rise; one sign is that corporate profits and markups have been increasing in the era of automation and digitalization . AI could reinforce this trend, as “gains in productivity from firms that adopt AI will likely boost capital returns” , benefiting investors and high-wealth individuals . Unless countervailing forces emerge, wealth inequality could deepen , as those with capital to invest in AI reap most of the gains, while those relying on labor income face pressure. Superstar Firms and Winner-Take-All Effects: Because of the scalability of AI (non-rivalry) we discussed, the top AI-performing firms can capture outsized market shares. This can translate into “superstar” economic dynamics , where a handful of companies or entrepreneurs accumulate enormous wealth. We already see hints of this with big tech companies dominating their sectors globally – AI could amplify it, especially if one company’s AI becomes markedly superior at certain tasks (e.g., a single AI platform that powers most legal document review or medical diagnostics worldwide). Such concentration can further skew income distribution, and also raises barriers for new entrants (which affects long-term innovation and consumer choice). All the above points to rising inequality between different groups of humans. But AI also forces us to consider a more unprecedented idea: the role of non-human agents in the economy. Let’s call this the29 • 30 30 30 • 16 31 • 7 economic agency paradox . Classical economics revolves around two fundamental agents – households (people) who supply labor and consume goods, and firms that produce goods using labor and capital. In a world where AI entities (machines, algorithms) perform labor-like functions, we encounter odd questions: Who, exactly, is doing the work and who should get the income from it? AI “workers” do not have needs, desires, or rights; they do not consume, and they cannot hold property or money in their own name (at least under current law). This creates a paradox of production without clear personal agency: AI as Labor or Capital? From an accounting perspective, if a company uses an AI to replace an employee, the AI is treated as part of capital (an owned tool). The expenditure shifts from the wage bill to either an investment (if they build or buy the AI) or an operational cost paid to an AI service provider . In either case, it’s not labor income. Thus, national income accounting will record a drop in labor compensation and a rise in gross profits or capital income. Over time, if AI-driven automation becomes widespread, we’d expect the labor share of GDP to shrink significantly, breaking a long-held stability assumption (Kaldor’s stylized facts historically assumed roughly constant labor share). Some recent studies already document a declining labor share in many countries and attribute part of it to automation and digital technology. AI could accelerate that decline, unless new types of human jobs replace the old at sufficient scale (which is uncertain). Who Consumes What AI Produces? In a thought experiment, imagine an economy where AI and machines produce all essentials efficiently, but very few humans are needed in production. If those AI and machines are owned by a small segment of society, then wealth concentrates to them, and the rest of the population has little income. This is problematic because broad consumption demand could fall – economies need consumers. We could end up with overcapacity: the AI can produce plenty, but people can’t afford to buy it because they have lost their jobs. One can argue that prices will drop so much that goods become very cheap (the abundance scenario), but even free goods don’t pay the bills for housing, etc., and not everything can be free. This line of reasoning has some economists and technologists suggesting redistributive mechanisms (like Universal Basic Income, UBI, or negative income taxes funded by taxing AI-driven profits) to ensure purchasing power remains widespread. Indeed, the conversation around UBI has gained traction alongside AI’s rise, with the idea that if AI and robots do most work, humans should still benefit via an income floor . While speculative in the extreme form, we’re already seeing early policy responses : for example, proposals to tax automation or AI systems in lieu of payroll taxes (sometimes called a “robot tax”) to fund social programs. The notion is to mimic how human labor would contribute to society (through taxes and spending) even if that labor is now done by machines. Legal and Ethical Agency: There’s also a legal dimension. As AI takes on tasks like driving vehicles, diagnosing patients, or making business decisions, legal frameworks struggle with assigning responsibility. Currently, a corporation or its appointed human is ultimately accountable. We might see new legal definitions emerge (for instance, EU discussions about an “electronic personhood” status for autonomous systems have occurred, though controversially). If AIs were ever granted a form of agency or personhood (even limited), that would upend many assumptions – they could, in theory, own assets or sign contracts. But such developments are still largely hypothetical and fraught with ethical concerns. For now, the reality is that AI acts as an extension of its owner or operator , so agency in economic terms actually concentrates: one human or firm can leverage thousands of AIs as “workers” without increasing the number of legal agents. A manager with an army of AI assistants doesn’t need to feed or pay them – just the power bill – and there’s no collective bargaining for AIs. This asymmetry could further tilt bargaining power away from labor .• • • 8 Considering these issues, most analyses conclude that, without intervention, AI is poised to increase inequality within countries . Highly skilled and capital-rich individuals likely gain, while others face job insecurity or stagnant incomes. This has serious societal implications: social safety nets and workforce development programs will need bolstering to manage the transition. The IMF explicitly calls for “comprehensive social safety nets and retraining programs for vulnerable workers” to make the AI transition more inclusive . Education systems will need to focus on skills that are complementary to AI (like complex problem-solving, human interaction, creativity) so that humans can find new niches alongside machines. In distributional terms, we may need new mechanisms for sharing AI-generated wealth – whether through taxation of high profits, data dividends, or ownership structures that give broader stakeholders a share in AI capital. In summary, the “economic agency paradox” highlights that AI disaggregates production from human workers , potentially creating a surplus of goods but a deficit of earning opportunities for people. The economy can produce more, but who benefits? Navigating this will require innovative economic thinking, likely drawing on both classical ideas (tax and redistribute) and novel concepts (data as labor , or AI cooperatives, etc.). The challenge for economists is to ensure that human well-being remains at the center of an economy increasingly run by non-human agents. Baumol’s Cost Disease: Will AI Cure It or Worsen It? “Baumol’s cost disease” is an economic phenomenon observed when technological progress boosts productivity in some sectors but not in others, causing the slower-growth sectors to become relatively more expensive over time. William Baumol originally noted how industries like manufacturing had huge productivity gains (hence falling relative costs), whereas labor-intensive services (education, healthcare, live performances, etc.) saw little productivity growth but rising wages (because they must compete for labor with the productive sectors). The result is that the stagnant sectors consume an ever-larger share of income to deliver the same output – e.g., a string quartet performance costs many times more today than in 1800 (adjusted for inflation), simply because musicians’ time has gotten costlier relative to goods, despite the quartet being no more efficient at producing music than centuries ago. This cost disease leads to affordability issues for essential services and a drag on overall economic growth as resources shift to low- productivity uses. Where does AI fit into this story? On one hand, AI is a technology that promises to finally increase productivity in some of those stubborn service sectors; on the other hand, if its adoption is uneven, it could actually exacerbate the imbalances. AI as a Cure: Optimistically, AI could be the tool that brings productivity growth to services like healthcare, education, and personal services , thereby easing cost pressures. For example, if AI tutors can personalize education and allow one human teacher to effectively teach 10x more students with comparable outcomes, the productivity of education would rise and the cost (per student) could fall. Likewise, if AI assistants handle routine diagnostics or paperwork for doctors and nurses, medical professionals can see more patients or spend more time on direct care, potentially improving productivity in healthcare. A Forbes analysis even touted that “AI can cure Baumol’s cost disease – but only if we want it to,” implying that with determined application, sectors that have lagged can finally catch up in efficiency. Indeed, studies are already finding cases of AI boosting service productivity: a cited example is customer service – AI chat assistance led to about a 14% increase in issues resolved per hour by human agents . In knowledge-intensive roles (like programming or design),3129 29 • 32 9 early evidence suggests even larger gains as AI handles routine drafting and allows humans to focus on creative tweaks. If these gains are realized across the spectrum of services, the historical cost spiral could be arrested or reversed. In quantitative terms, one study predicted that AI’s diffusion could add on the order of 0.5 percentage points to annual productivity growth in service- heavy economies , helping lift the long-term growth trend. AI and Sectoral Shifts: On the other hand, there’s a scenario where AI greatly improves productivity in some sectors more than others, potentially intensifying Baumol effects in the short run . Recall that if one sector becomes hyper-productive, the relative price of its outputs falls, and consumers spend a smaller share of income on those goods, reallocating spending to other sectors (often those with slower productivity growth, like leisure, education, healthcare). One academic perspective noted that if AI-driven productivity gains are concentrated in certain product categories with inelastic demand, those sectors’ share of expenditure will shrink, “shifting activity toward slower-growing sectors and muting aggregate productivity growth à la Baumol” . In other words, if AI makes food and manufactured goods extremely cheap, people won’t keep buying infinite amounts of them; instead, they’ll direct more of their spending to things like vacations, dining experiences, or boutique services – which might not see the same productivity leap. This could result in the paradox of plenty: huge efficiency in some domains but most money being spent in the laggard domains, dragging on overall GDP growth rates. Uneven Adoption and the Baumol Effect: Currently, AI adoption is quite uneven across industries , and this could cause a Baumol-like imbalance if it persists. Surveys show that only about 5–15% of firms (depending on country and sector) have adopted AI in their processes so far . Leading sectors include IT, finance, and some manufacturing, whereas areas like healthcare, education, and government services lag behind (often due to regulatory and structural barriers, or lack of economic incentive to cut labor). If this pattern continues – fast improvement where competition is fierce and tech is friendly, stagnation where it’s hard to implement – we will see the benefits of AI concentrated in a few sectors . Those sectors might experience rapid cost declines and possibly even contraction in employment (because they become so efficient), while the rest of the economy remains high-cost and labor-intensive. This is essentially a Baumol dynamic, where the AI-rich sectors’ relative share of GDP falls as their prices drop, and resources flow into the AI-poor sectors that haven’t improved (whose relative prices then rise). The net effect could be a temporary slowdown in aggregate productivity growth despite pockets of spectacular AI-driven gains – simply because the weight shifts to the stagnant parts. Some economists argue this is one reason we haven’t yet seen big productivity jumps at the national level: AI is booming in tech, but healthcare and other big slices of GDP are unchanged or even getting more expensive. Implications for Inequality and Access: Baumol’s cost disease has a human angle – it tends to make essential services like healthcare and education more expensive over time, straining lower- income households. Baumol himself observed that “the cost disease disproportionately affects the poor,” as they struggle to afford increasingly pricey necessities like medical care . If AI fails to penetrate these sectors, or if its benefits are not passed on in prices, we could see an exacerbation of this problem: e.g., high-tech medical AI is used by hospitals to improve outcomes, but healthcare costs don’t fall – profits do instead – keeping care expensive. Alternatively, if AI does help these services become cheaper , it could be a great equalizer , making quality education, advice, or healthcare more universally affordable. It largely hinges on the choice and policy : whether we aggressively deploy AI for public benefit in these areas or not. Some studies note that current cost5 • 33 • 34 35 • 36 10 containment in sectors like healthcare has faltered because solutions didn’t address root productivity issues ; AI might address some (e.g. automating documentation, optimizing operations), but only if adopted and integrated effectively. In conclusion, AI has the potential to alleviate Baumol’s cost disease by raising productivity in lagging sectors, but this outcome is not automatic. It will require overcoming adoption hurdles and perhaps rethinking service delivery models. If we “want it to” – meaning if society directs effort toward applying AI in, say, public education or elder care – there’s hope to bend the cost curves. On the other hand, if AI deployment remains skewed or if demand shifts nullify some gains, the relative cost problem could persist. For economists, this means we should track not just the average productivity improvements, but their distribution across sectors. The goal should be broad-based productivity growth. If AI’s benefits are narrowly concentrated, policy might aim to spread them (for instance, government funding for AI tools in healthcare, or incentives for tech diffusion to smaller firms in service industries). Either way, the Baumol framework reminds us that transformative tech like AI can have counterintuitive macro effects . Even as it boosts capabilities, where those boosts occur matters. A balanced growth path – where AI lifts all boats, not just the speedboats – is the ideal scenario to strive for . “Statutory” Jobs and the Human Role in an AI Economy Finally, we turn to an intriguing concept that came up in our discussion: “statutory jobs.” These are jobs that remain filled by humans not necessarily because humans are more productive at them, but because laws, regulations, or societal norms require a human in the loop . In an AI-rich future, there may be tasks that AI could do, but we deliberately or legally mandate human involvement – for reasons of safety, accountability, or ethical preference. Recognizing these is important for understanding which jobs are likely to persist and why, even as technology advances. A “statutory job” can refer to several scenarios: Legally Required Human Oversight: Certain industries have regulations that explicitly or implicitly demand a human decision-maker or supervisor . For example, many countries’ laws require that a licensed human driver be responsible for a moving vehicle on public roads. Even if a car is capable of driving autonomously, the law might still require a human in the driver’s seat to take over in emergencies (as is currently the case in testing scenarios). Similarly, medical practice typically requires a human physician to sign off on diagnoses and treatments; an AI can assist, but it cannot (today) legally prescribe medication on its own. Financial audits and legal documents often need human signatures for validity. In aviation, autopilots fly planes for the most part, but regulations require human pilots to be present and in charge. These are all examples of roles where, by statute or regulation, a human must be “in the loop.” One commentator described statutory jobs as “jobs where a human is legally required for one reason or another — licensure, insurance, signatures, etc.” . In essence, the law hasn’t caught up to allowing AI to fully replace the human, either due to prudence or lobby influence or simply the slow pace of legal change relative to technology. Accountability and Insurance: Even absent explicit laws, sometimes the liability framework forces a human presence. For instance, an insurance company might refuse to underwrite a fully autonomous operation without a human accountable. Companies might keep a human operator on staff to take blame if something goes wrong, as AI cannot be sued or jailed. This creates jobs that37 • 38 • 11 are more about responsibility than about doing the bulk of the work. Think of a security guard overseeing a fleet of surveillance drones, or a factory floor “attendant” monitoring automated machines – one human might oversee dozens of AI agents, but their presence is legally required to satisfy liability concerns. These humans might intervene 0.1% of the time, but regulations or insurance demand they be there 100% of the time. Human Trust and Ethical Preference: Some jobs will remain human because society desires a human touch or accountability , even if not strictly required by law. For example, many people may be uncomfortable with an AI judge in a courtroom – they expect a human to mete out justice, so even if an AI could analyze cases, the judge’s role may remain human by convention (or by future law reflecting that norm). Care jobs are another area: families might demand that childcare or eldercare involve real human caregivers, valuing empathy and genuine emotional connection. These could be considered “statutory” in a loose sense of mandated by social norms or regulations in care facilities. A futurist discussion on life post-AGI suggested that “jobs that are experience-based, require human touch, or are mandated by law will likely remain resistant to AGI” , citing examples like tour guides, massage therapists, entertainers, nursing and childcare, and statutory roles . In other words, roles where either a human element is the very point (massages, personal entertainment, etc.) or where we codify the requirement for a human (law, medicine, etc.) will be among the last to automate fully. Meaning and Authenticity-Based Jobs: Relatedly, there may be a class of work that persists because we attach meaning to the human effort itself. Artistic and cultural endeavors often fall here. For instance, even if an AI can paint a masterpiece or compose a symphony, there will be audiences who prefer a work knowing it was created by a human artist, as it carries a story of human creativity. These “meaning” jobs (some have dubbed this the “meaning economy”) might actually flourish as automated production frees people to pursue creative, artisanal, or service-oriented passions. They might not be mandated by law, but they are protected by human preference. An extreme vision holds that once AI handles all necessities, human work will shift to things we want to do – art, exploration, interpersonal services – valued for their authenticity or experiential quality. We see early hints in the premium people place on “handmade” or “locally crafted” goods even when cheaper factory versions exist. The concept of statutory (and relatedly, meaning-based) jobs highlights a crucial point: not all economic value is about efficiency . Sometimes we will choose a less efficient route because it aligns with human values, safety, or trust. In an AI-saturated economy, we may very well designate roles for humans to ensure oversight, to preserve human dignity, or simply to maintain a connection to the human experience. For example, even if AI could theoretically handle all childcare, societies might insist on human caregivers for moral and developmental reasons. Governments could enact laws to that effect, effectively creating “statutory employment” for certain caregiving or oversight roles as a way to guarantee jobs for humans and preserve social norms. From an economic perspective, these statutory jobs could be seen as a form of labor market intervention – they are jobs maintained by regulation, potentially above the level the pure market would demand. There is historical precedent: regulations often require minimum staffing (say, a minimum nurse-to-patient ratio in hospitals, or requiring two crew members in certain train operations even if one might suffice). In a future with abundant AI, such rules might proliferate to deliberately slow automation in critical areas or ensure human presence. This could be a policy lever to mitigate unemployment: for instance, laws might• 39 • 12 mandate that every AI-operated trucking fleet still employ a human supervisor for every X trucks, or require that AI-generated news is reviewed by a human editor , etc. While such rules might be justified by safety or quality concerns initially, they also function to preserve employment. Of course, there is a balance to be struck. Over-relying on statutory job protections could lead to inefficiency or “pretend work” scenarios , where humans are essentially paid to watch machines do the actual work. This touches on the concept of “bullshit jobs” (coined by David Graeber) – roles that exist mainly for appearances or due to bureaucracy. If taken too far , creating lots of artificial jobs could undermine the very productivity gains AI offers. The hope would be that humans freed by AI can transition to genuinely valuable roles (including those providing human connection or creativity) rather than make- work. But in the short term, and to ease transitions, some degree of mandated human-involvement policy might be prudent . In summary, statutory jobs will likely form a protective bubble of human employment in the AI era , encompassing things we insist remain human-driven. This includes roles legally mandated to have a human responsible, as well as roles preserved by ethical, cultural, or emotional choice. Identifying these areas can help workers and policymakers focus on where human labor has durable comparative advantage or societal backing. It also underscores that the future of work is not solely a tech issue but a normative one: we will decide, through laws and values, how and where we want humans in the loop. Economically, this can be seen as a way to ensure resilience and trust – for instance, having human pilots not because they’re better 99.9% of the time, but for the 0.1% of emergencies and for passenger confidence. Statutory jobs thus serve as a reminder that even in a hyper-automated economy, humans aren’t obsolete – they may play different, sometimes supervisory or empathetic, roles which the market alone might not value but society chooses to uphold. Conclusion: Toward a Post-Labor Economics The rise of advanced AI compels us to re-examine many fundamental economic assumptions. Unlike traditional automation, AI is general-purpose , intangible , and non-rival , with near-zero marginal costs and a dependence on high energy inputs. These qualities make it a different kind of automation – one that can scale without the usual limits of physical capital or human labor , and one that could potentially produce an abundance of output with minimal human input . This promises great gains in productivity and efficiency, but also poses challenges in distribution, labor displacement, and infrastructure demands. From our exploration, several key themes emerge: Non-Rivalry and Intangibles: AI’s replicability means knowledge can spread at low cost, enabling rapid cumulative progress. But to harness this, we need frameworks that encourage sharing of AI benefits without stifling innovation incentives. The rise of intangibles in investment indicates that future wealth will increasingly lie in intellectual and data-driven assets. Economies that understand this – by fostering education, R&D, and digital infrastructure – will thrive . Those that cling solely to tangible industrial-era strategies may fall behind. Productivity and Complementarity: AI can boost total factor productivity significantly, but realizing its full potential involves complementary changes – reorganizing firms, retraining workers, updating regulations. Early evidence is encouraging (e.g. double-digit productivity lifts in some applications ), and forecasts suggest a meaningful uptick in growth if adoption spreads . But diffusion is• 40 4140 • 32 5 13 key: broad adoption across sectors (including laggards like health and education) is needed to avoid a two-speed economy and to cure cost disease. Otherwise, we risk AI’s gains being isolated in pockets, with the Baumol effect tempering macro gains. Labor and Distribution: AI’s labor-substituting power is unprecedented in scope. It heightens the urgency to address inequality. Without intervention, we likely see a falling labor share , wage polarization, and wealth concentrating with AI owners . To counter this, policies such as stronger social safety nets, lifelong learning programs, and perhaps new redistribution mechanisms (like taxing AI-driven profits or data use) will be essential . Society may also need to reassess notions of work and income – decoupling livelihood from traditional employment, if “full employment” is no longer a given in a heavily automated economy. Concepts like UBI, job guarantees, or shorter work weeks paid by productivity gains, enter serious consideration in a post- labor scenario. Energy and Infrastructure: AI’s promise will fizzle without robust support from the physical world – namely, electric power and computing hardware . Planning for greatly expanded electricity demand , upgrading grid capacity, and accelerating the shift to clean energy (to avoid emissions spikes ) are all critical. There’s an opportunity to align AI’s rise with green energy growth, making sustainable power the backbone of the new economy. Failing to do so could create bottlenecks or climate trade-offs that undermine the benefits of AI. Additionally, supply chains for advanced chips and data center equipment become strategic assets; ensuring their resilience and broad access (avoiding chokepoints controlled by a few nations or firms) will have economic and security implications. Rethinking Economic Metrics and Models: Economists may need to adapt how we measure and model the economy. GDP and productivity measures should account for intangibles and free digital services more accurately, or we risk misinterpreting the impact of AI. Traditional models of growth that assume exogenous technological progress might shift to models with AI as an explicit factor – possibly exhibiting increasing returns and non-linear growth if handled well . Distributional impacts might be better captured by moving beyond averages (GDP per capita) to medians or inequality indices when evaluating progress in the AI age. And fundamentally, the presence of non- human productive agents might warrant conceptual expansions – perhaps treating AI as a new factor of production that is neither labor nor capital in the usual sense, but something hybrid that demands new theoretical treatment. Human Purpose and Policy Choices: Ultimately, the trajectory of an AI-driven economy is not predetermined by technology alone; it will be shaped by our choices . We can choose to use AI to augment humans rather than replace them wholesale – for instance, using AI in a “centaur” model where each worker is far more productive with AI tools, rather than pure automation. We can decide whether to implement statutory requirements for human involvement in certain domains, balancing efficiency with ethics and employment . We also collectively decide how to utilize the fruits of AI productivity – whether to allow them to accrue to a few or to broadly distribute them for societal gain. The conversation with my friend that prompted this report is itself a microcosm of this needed discourse: we must educate one another on the true nature of AI’s economic impact so that outdated assumptions don’t lead us astray. Economists, in particular , should update their mental models: AI is not just another machine, it breaks many classical patterns (non-rivalry, intangibility, agency) and thus demands innovative economic thinking.• 3129 29 • 2142 26 • 943 • 38 14 In conclusion, AI has the potential to usher in an era of unprecedented prosperity – a world where goods and services are produced abundantly and at low cost, where humans are freed from drudgery to pursue higher endeavors. But reaching that world, and ensuring it is one of broadly shared prosperity, requires deft navigation of the challenges outlined here. Non-rival AI means we have a chance at near-zero cost production for many things, but we must manage the transition so that the benefits don’t bypass large segments of society. Post-labor economics will need to address how value and dignity for individuals are maintained when their labor is no longer needed in the same way. The downstream consequences – from energy systems to education, from inequality to new job definitions – are all interconnected pieces of the puzzle. AI is a different kind of automation, indeed a different kind of economic revolution. By recognizing its unique characteristics – general-purpose scope, non-rival scalability, and novel constraints – we can better craft policies and institutions to harness it. If we get it right, AI can be the engine of a new prosperity that elevates all of humanity. If we mismanage it, we could face a polarized economy of plenty for some and precarity for others. The stakes are high, but with informed understanding (as we’ve endeavored to compile in this report) and proactive strategy, we can aim for the former scenario: an AI-augmented economy that is dynamic, equitable, and sustainable – truly a new chapter in economic development. Footnotes: Brynjolfsson, E., Rock, D., & Syverson, C. Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics . NBER Working Paper 24001 (2017). – AI exhibits characteristics of a general- purpose technology, implying broad economic effects beyond narrow applications. Georgieva, K. AI Will Transform the Global Economy. Let’s Make Sure It Benefits Humanity. IMF Blog (Jan 14, 2024). – AI’s impact is distinguished by reaching high-skilled jobs; about 60% of jobs in advanced economies could be affected by AI, including many high-skill roles, unlike past automation which focused on routine tasks. Goover SEO – Baumol’s Cost Disease in Modern Economies (AI section). (2024) – Studies show sectoral productivity gains from AI (e.g., ~14% in customer service tasks). Projections suggest AI could contribute 0.25–0.9 percentage points to annual labor productivity growth in the US over the next decade, depending on adoption rates. Lorenz, E. et al. Artificial Intelligence and its Effect on Competition and Factor Income Shares. (2023) – AI can be modeled as a non-rival (but excludable) input: one firm’s use of an AI algorithm does not preclude another’s use. In contrast to labor or traditional capital, which are rivalrous, all firms can simultaneously utilize a given stock of AI knowledge. AFP (via TechXplore). “Investments rise in data, AI, outpacing physical assets: UN.” (Jul 9, 2025). – According to WIPO, investment in intangible assets like software, data, and AI grew three times faster in 2024 than investment in physical assets. From 2008–2024 intangible investment grew ~4% annually (versus 1% for tangibles), indicating a shift in how economies grow and compete, driven by technological and digital innovation. Voss, G. et al. Intangible Capital as a Source of Company Growth. – Empirical analyses find that markups and profit concentration are higher in digital-intensive industries. As firms leverage non-rival intangible1 67 4 944 1140 16 15 assets (software, AI), markets can trend towards winner-take-all outcomes, raising average markups in high-ICT sectors relative to low-ICT sectors. Bogmans, C. et al. “AI Needs More Abundant Power Supplies to Keep Driving Economic Growth.” IMF Blog (May 13, 2025). – Data centers consumed ~500 TWh of electricity in 2023 (about as much as France or Germany), more than double their 2015 level. OPEC projections estimate this could triple to ~1500 TWh by 2030, which would be on par with India’s current electricity usage and 1.5× the projected consumption of all electric vehicles by 2030, underscoring AI’s huge power demands. University of Michigan News. “Optimization could cut the carbon footprint of AI training by up to 75%.” (Apr 17, 2023). – Training the GPT-3 model (175 billion parameters) one time consumed ~1,287 MWh of electricity, enough to power an average U.S. household for 120 years. This exemplifies the extreme energy intensity of state-of-the-art AI model training at “extreme scales.” Bogmans et al., IMF (2025) – If electricity supply fails to keep pace with AI-driven demand, prices could rise steeply, hurting consumers and potentially stalling AI adoption. Under current policies, the increased power use for AI from 2025–2030 could add ~1.7 gigatons CO₂ emissions (roughly Italy’s five-year energy emissions), highlighting the environmental stakes and need for clean energy expansion. Georgieva, IMF (2024) – AI’s gains may disproportionately go to higher-income workers (if AI complements their roles) and to capital owners (via higher returns on AI-augmented firms), thereby increasing income and wealth inequality. In most scenarios analyzed, AI is expected to widen overall inequality, necessitating proactive policies like social safety nets and retraining to ensure inclusive benefits. Shapiro, D. “The Great Dislocation” (Substack, 2023) – Defines “statutory jobs” as those where a human is legally required (due to licensure, insurance, signatures, etc.), even if automation is possible. Such requirements ensure human involvement in certain processes despite technological capability for full automation. McCoy, J. “What will AGI look like? A world run by AI.” (YesChat blog, 2023) – Anticipates that jobs centered on human experience, personal touch, or legal mandates will resist full automation. Examples cited include legally mandated roles (“statutory jobs”), and roles like tour guides, entertainers, or caregivers where human interaction is valued. These areas are expected to remain in demand post-AGI due to either normative requirements or consumer preference for human-provided experiences. Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics https://www.nber .org/system/files/working_papers/w24001/w24001.pdf AI and the Productivity Paradox - Bruegel https://www.bruegel.org/blog-post/ai-and-productivity-paradox AI Will Transform the Global Economy. Let’s Make Sure It Benefits Humanity. https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity Baumol's Cost Disease in Modern Economies https://seo.goover .ai/report/202412/go-public-report-en-6c971e47-35c8-4587-86dc-14f7730c72fa-0-0.html21 22 20 24 26 31 29 38 39 133 2 3 6 729 30 31 4 519 32 34 35 36 37 16 Artificial Intelligence and its Effect on Competition and Factor Income Shares https://www.econstor .eu/bitstream/10419/290195/1/vfs-2023-pid-86929rev.pdf Investments rise in data, AI, outpacing physical assets: UN https://techxplore.com/news/2025-07-investments-ai-outpacing-physical-assets.html Optimization could cut the carbon footprint of AI training by up to 75% | University of Michigan News https://news.umich.edu/optimization-could-cut-the-carbon-footprint-of-ai-training-by-up-to-75/ AI Needs More Abundant Power Supplies to Keep Driving Economic Growth https://www.imf.org/en/Blogs/Articles/2025/05/13/ai-needs-more-abundant-power-supplies-to-keep-driving-economic-growth The 'Great Dislocation' will be more painful than anyone realizes https://daveshap.substack.com/p/the-great-dislocation-will-be-more What will AGI look like? A world run by AI. https://www.yeschat.ai/blog-What-will-AGI-look-like-A-world-run-by-AI-253478 910 16 17 18 43 44 11 12 13 14 15 40 41 20 28 21 22 23 24 25 26 27 42 38 39 17