AI as a General-Purpose Technology Introduction Artificial Intelligence (AI) is increasingly recognized as a transformative general-purpose technology (GPT) on par with historical engines of change like electricity and the steam engine. Leading experts highlight AI’s pervasive utility: for example, Andrew Ng has called AI “the new electricity,” noting that it can power countless applications across sectors just as electricity revolutionized everything a century ago . In testimony to the U.S. Senate, Ng emphasized that AI is a GPT “similar to electricity and the internet,” with use cases ranging from answering questions and tutoring students to generating art, aiding medical diagnosis, underwriting loans, customer support, and self-driving cars . In other words, AI isn’t a single tool for one job – it’s a general technology platform with myriad uses. This broad applicability, combined with rapid improvements in capability and falling costs, has convinced many economists and technologists that AI meets all the criteria of a GPT and will fundamentally reshape economies. The following report will detail the definition of GPT, illustrate how modern AI (especially deep learning and reinforcement learning) fits that definition through empirical examples, and examine trajectories indicating AI’s continued expansion and proliferation as a foundational technology. By the end, it should be clear to any economist that AI is indeed a general-purpose technology in the fullest sense. What Are General-Purpose Technologies? General-purpose technologies are technologies so fundamental that they catalyze widespread economic and social transformations. In economic history, a handful of GPTs (e.g. the steam engine, electricity, internal combustion engine, computers) have driven eras of growth by enabling new processes across nearly all industries . Economists define GPTs by certain key characteristics. Notably, Bresnahan and Trajtenberg (1996) identified three defining features : Pervasiveness: A GPT spreads to most sectors of the economy, rather than being confined to one niche . In other words, it is a general enabling technology used broadly across industries. Improvement over time: A GPT gets better and cheaper over time , continually lowering the costs for its users . The technology has substantial scope for refinement and efficiency gains, driving down prices or improving performance year after year . Innovation spawning: A GPT facilitates new innovations – it makes it easier to invent and produce new products and processes that were not possible before . In essence, it creates spillover effects by enabling complementary innovations in downstream applications. Other scholars offer similar criteria. Lipsey and Carlaw (2005) , for example, describe a GPT as “a single, recognizable generic technology” that initially has much scope for improvement, becomes widely used across the economy, has many different uses, and creates many spillover effects . In plain terms, a true GPT starts as a novel invention but eventually permeates the entire economy , continually advances in capability, and spawns a wave of secondary innovations (new applications, processes, even industries built on it). Classic GPTs like electricity or the internet clearly fit this mold – and as we will see, so does artificial intelligence.1 1 23 4 • 4 • 4 • 4 5 1 It’s also important to note some economic principles tied to GPTs. One is the idea of non-rivalry in consumption: many GPTs (especially modern digital technologies like software and AI) are largely intangible and can be replicated at near-zero cost. Once developed, they can be used by many people simultaneously without being “used up.” In traditional terms, knowledge-based technologies are non- rival goods – one person’s use of an idea or algorithm doesn’t prevent others from using it . AI exemplifies this: a trained AI model (an LLM, for instance) can be deployed to countless users or tasks at virtually no additional cost, unlike a physical machine that can only do one job at a time. This non-rival, zero- marginal-cost nature of AI’s “intelligence” input amplifies its reach and impact . It means AI can spread and scale faster than many past technologies, as it isn’t bottlenecked by physical production. These characteristics – economy-wide reach, continuous improvement, complementary innovation, and an ability to scale cheaply – set the stage for AI as a GPT. AI’s Broad Application Across Sectors (Pervasiveness) A core test of any GPT is whether it is widely applicable across different industries and uses . Modern AI, especially the techniques of deep learning (neural networks trained on large data) and reinforcement learning (AI agents learning via feedback), passes this test with flying colors. We now see AI systems being deployed in virtually every sector of the economy . A brief survey of examples illustrates just how pervasive AI’s reach has become: Healthcare: Deep learning models can analyze medical images (like X-rays, MRIs) to detect diseases (e.g. spotting tumors or diabetic retinopathy) with accuracy rivaling or exceeding human doctors. AI systems assist in diagnosing conditions, predicting patient outcomes, personalizing treatment plans, and even discovering new drugs. For instance, AI image recognition helps radiologists flag abnormalities, and machine learning models sift through molecular data to identify promising new pharmaceutical compounds. These applications improve healthcare delivery and outcomes. (Ng notes AI is already used for “detecting disease,” among other tasks .) Finance: AI algorithms are widely used in fraud detection (monitoring transactions for anomalies), algorithmic trading and portfolio management, credit scoring and loan underwriting, and customer service via chatbots. Banks and fintech firms use deep learning to detect suspicious patterns in real- time (reducing fraud), while lending institutions use AI to analyze creditworthiness beyond traditional credit scores. In fact, AI-driven decision systems now help decide whether to underwrite loans and manage financial risk . The finance sector has been an early adopter of AI to increase speed and accuracy in data-heavy, predictive tasks. Transportation and Manufacturing: In transport, AI underpins autonomous vehicles and advanced driver-assistance systems – self-driving car prototypes rely on deep neural networks for vision and control. AI optimizes logistics and supply chains (routing deliveries, managing inventory), and in manufacturing it enables predictive maintenance (anticipating equipment failures from sensor data), quality control via computer vision, and automated assembly with robotics. Reinforcement learning has even been applied to industrial control problems – famously, Google’s DeepMind trained an AI system to manage data center cooling systems more efficiently. By learning to adjust cooling in real-time, the AI was able to cut energy usage for cooling by up to 40% in Google’s data centers , a massive efficiency gain in an otherwise mature industry. This example shows AI’s power to optimize complex physical operations (in this case, reducing electricity6 6 • 1 • 7 • 8 2 consumption and costs substantially) – a clear demonstration of cross-domain applicability, from gaming algorithms to industrial engineering. Retail and Customer Service: Businesses use AI for demand forecasting, optimizing pricing, managing inventory, and personalizing marketing. Online retailers employ recommender systems (deep learning models) to suggest products and target ads to consumers. Chatbots and virtual assistants (powered by natural language processing) are handling customer inquiries at scale in e- commerce and service industries. These AI-driven systems improve efficiency and can operate 24/7, scaling customer support without linear increases in staffing. Many companies also use AI to analyze customer sentiment (from surveys or social media) and improve user experience. In Ng’s testimony, he highlighted that today’s AI is useful as a “customer support” agent and even a copyeditor or brainstorming partner in business contexts – roles that appear in myriad industries. Education and Training: AI tutors and learning platforms provide personalized education by adapting to each student’s level and progress. For example, AI-driven tutoring systems can coach students in mathematics or language learning, giving hints and feedback tailored to the individual. Large language models are now being used to create interactive study aids and answer students’ questions in natural language. This personalizes learning at scale, something previously not feasible. Indeed, Ng notes tutoring students as one of the emergent use cases of modern AI . In corporate training, AI systems can similarly personalize content for employee development. Science and R&D: AI is accelerating scientific discovery. A striking example is DeepMind’s AlphaFold , a deep learning system that effectively solved the 50-year-old “protein folding” problem – predicting 3D structures of proteins from their amino acid sequence. AlphaFold’s breakthrough has “revolutionized protein folding, unlocking potential for everything from therapeutics to materials science,” according to observers . By open-sourcing AlphaFold’s results (predicting structures for essentially all catalogued proteins), DeepMind has provided researchers worldwide a tool that is speeding up biotech R&D and drug discovery. In materials science, AI models are being used to discover new materials and chemicals (for batteries, enzymes, etc.) far faster than trial-and- error lab work. In these ways, AI acts as a general research tool , amplifying innovation in domains well beyond computer science. The spillover benefits to society (new medicines, sustainable materials, etc.) could be enormous – a hallmark of a GPT. These examples are merely scratching the surface. AI’s generality is evidenced by its presence in virtually every field : agriculture (crop monitoring and automated harvesting robots), energy (smart grids optimizing power distribution, AI for climate modeling and clean tech), law (AI tools for document review and legal research), art and media (generative AI creating images, music, and writing), and more. Importantly, the same core AI techniques (especially deep neural networks) underpin these diverse applications. A convolutional neural network that analyzes medical scans is not fundamentally different from one detecting defects on a factory line – the underlying algorithms generalize across problems once trained on the right data. Likewise, a reinforcement learning algorithm that mastered the game of Go can be repurposed (with modifications) to manage real-world logistics or , as Google showed, to optimize chip design. In 2020, Google researchers applied reinforcement learning to the notoriously complex task of computer chip floorplanning (arranging circuit components on a chip) – a problem engineers struggled to automate for decades. Their AI, later named AlphaChip , treats chip layout like a game: it places components one by one and learns from a reward signal measuring performance. Remarkably, AlphaChip can generate “superhuman” chip layouts in a few hours (versus weeks or months of human effort),• 9 • 10 • 11 3 and its designs have been used in Google’s actual AI accelerator chips deployed worldwide . This is a powerful proof that AI’s general problem-solving ability is not confined to toy domains – it can tackle hard engineering design challenges and produce better-than-human solutions. From board games to boardrooms and labs, AI’s versatility across tasks and industries is exactly what we expect from a GPT . It is broadly useful everywhere , much like electricity found a use in every corner of the economy in its day. Rapid Improvement in AI Capabilities (Improvement Trajectory) Another essential characteristic of a GPT is that the technology improves dramatically over time , driving down costs or boosting productivity for its users. AI is on a rapid improvement trajectory on multiple fronts: performance, efficiency, and ease of use. In the past decade, thanks to better algorithms, more data, and more powerful computing hardware, AI capabilities have advanced at an astonishing pace – far faster than most general-purpose technologies of the past . Raw performance gains are evident in many domains of AI. A striking recent example comes from language models : OpenAI’s GPT series. In late 2022, OpenAI released GPT-3.5 (the model behind the initial ChatGPT), and just a few months later in March 2023 released GPT-4 , a more advanced model. The improvement was quantifiable. On a standardized exam like the U.S. bar exam (a test for law school graduates), GPT-3.5’s performance was around the bottom 10th percentile of human test-takers – essentially a failing grade. GPT-4, however , scored around the 90th percentile , outperforming the vast majority of human examinees . In other words, within a few months, AI went from barely passing a difficult professional exam to scoring among elite humans. Such leaps in capability across iterations are unprecedented; they highlight how quickly machine learning models are getting “smarter” as research progresses. Similarly, the “context window” (the amount of information a model can consider at once) expanded dramatically – state-of-the-art generative models went from handling a few pages of text in 2020 to about 300 pages of text by late 2023 . This expansion enables far more complex tasks (like analyzing long documents or multi-step reasoning) to be done by AI, again improving its usefulness over time. Crucially, costs are falling even as performance rises . The cost to train or run AI models has been plummeting due to both hardware improvements and algorithmic efficiency. For example, researchers have noted that tasks like image recognition that in 2012 required expensive, specialized hardware can now be done on a cheap smartphone chip – or that training a large neural network model today might cost only a fraction of what it did a few years ago, even for greater performance. This trend mirrors economies of scale and learning curves seen in prior GPTs (like how the price of electricity or computing dropped steadily after their introduction). AI is benefiting from a kind of “double Moore’s Law” : not only are processors (GPUs, TPUs, etc.) getting faster and cheaper , but AI algorithms themselves are becoming more efficient in data and compute usage. As a result, the unit cost of an AI “prediction” or decision has dropped dramatically, making it economically feasible to deploy AI widely. For instance, one analysis by technologists suggests that high-level “intelligence” is becoming an abundant, near zero-marginal-cost input for businesses, since once an AI model is trained, using it for additional tasks incurs only minimal incremental cost (mostly electricity) . In the words of an economic analysis, modern large AI models have turned intelligence into a “non-rival, zero-marginal-cost” resource , meaning any firm can tap into AI’s insights without depriving others and without significant variable cost . This is a profound shift – akin to an industrial revolution where machine power became cheap and ubiquitous, we now have cheap ubiquitous cognitive power .12 13 14 6 6 4 The speed of improvement in AI also exceeds that of many past technologies. Historically, even after a GPT was invented, it often took years or decades of incremental improvements before it reached full potential. Electricity, for example, required building out the grid infrastructure and improvements in generators and appliances over many years. AI, by contrast, leverages digital infrastructure already in place (the internet, cloud computing) and improves largely via software updates and new architectures. There is little physical lag – new algorithms can be deployed globally overnight. As MIT researcher Andrew McAfee points out, generative AI is diffusing and improving “far more quickly than preceding innovations” because of its accessibility and ease of distribution . Consumers and firms can access cutting-edge AI via the cloud instantly, without needing to install new hardware or wait for physical networks to be built. And AI’s learning-by-doing feedback loops (models getting better as they train on more data) mean continual improvement is baked in. All these factors contribute to an unprecedented acceleration in capability . In sum, AI exhibits the hallmark GPT pattern of rapid ongoing improvement . Each year (indeed, every few months in recent times) brings more powerful AI models that can tackle a wider range of tasks at lower cost. This dynamic of increasing performance and efficiency ensures that AI will continue to lower the cost of operations for its users and open up new possibilities – just as a true general-purpose enabling technology should. AI-Spurred Innovation and Spillovers (Complementary Innovations) Beyond being used in existing processes, a GPT typically catalyzes complementary innovations – it enables new products, services, or ways of doing things that were previously unimaginable. Artificial intelligence is already doing exactly that, acting as an innovation multiplier across the economy. By providing a new kind of “cognitive tool,” AI is allowing inventors, entrepreneurs, and firms to create novel applications and reimagine business processes from the ground up. One way to see AI’s innovation-spawning effect is in the explosion of new applications and startups leveraging AI capabilities. The emergence of powerful foundation models (like GPT-4 and other large language models) has essentially created a new platform upon which countless businesses are being built. Just as the introduction of electricity led to a wave of new electric appliances and machinery in the early 20th century, the introduction of easily accessible AI APIs and models is leading to a wave of new AI-driven solutions. For example, we now see startups offering AI-powered legal contract review, AI tools for generating marketing copy and ad designs, AI-driven tutoring platforms, virtual nursing assistants in healthcare, personalized news curators, and much more – applications that are new innovations in their own right , made possible by the general capabilities of underlying AI. Many of these were not feasible or cost-effective before. This broad-based entrepreneurial activity around AI is strong evidence that AI is spawning complementary innovations rather than being a narrow, one-off invention. Even within established organizations, AI is prompting a rethink of processes. McAfee’s analysis of generative AI notes that companies are not just using AI for individual tasks, but starting to “redesign multi-step, multi-group processes” and even whole workflows to capitalize on AI’s capabilities . In effect, AI can change how work is done – for instance, an insurance firm might redesign its claims processing pipeline to have AI automatically analyze documentation and flag complex cases to human adjusters, dramatically speeding up throughput. Or a manufacturer might reorganize production scheduling around AI predictions of demand and maintenance needs. These kinds of complementary process innovations are diffuse and happen over time, but they are crucial for realizing GPT-driven productivity gains. Historically, such complementary innovations (like factory redesigns to use electric motors in the 1900s, or business1516 17 5 reorganization around IT in the late 20th century) are what eventually drive the big productivity boosts from GPTs. We are now in the early stages of firms experimenting with and implementing AI-driven process changes. As McAfee observes, “generative AI is already improving the productivity and quality of many tasks... and the technology is beginning to be used to reimagine entire organizations ,” with the deep transformations carried out by innovators and entrepreneurs throughout the economy . This reimagining is exactly what we expect as a GPT takes hold. Another major spillover impact of AI is how it’s accelerating scientific and technological research – effectively serving as a meta-innovation that makes further innovation easier . We saw the example of AlphaFold unleashing new research in molecular biology. Similarly, AI is used in engineering (for optimizing designs, as with AlphaChip’s role in chip design), in chemistry (discovering new drug molecules or materials via generative models), in environmental science (AI models to model climate or design carbon-capture materials), and so on. These advances feed into innovations in other fields – new medicines, greener technologies, more efficient products – that AI helps unlock but aren’t “about AI” per se. In economics, such effects are often termed spillovers or second-wave innovations. By making certain hard problems more tractable (like analyzing huge data sets or searching enormous design spaces), AI is enabling breakthroughs elsewhere. This amplifying effect on the overall innovation ecosystem is a classic sign of a GPT: much as cheap steel and electricity enabled countless downstream inventions in the industrial era, AI is enabling breakthroughs in our modern knowledge economy. It’s worth noting that spin-off benefits and externalities of AI deployment are also emerging. For example, when one firm develops a powerful AI model and open-sources it or provides it as a service, other industries benefit without having to reinvent the wheel. The open-source AI movement (where models like Meta’s LLaMA or various open clones of GPT have been released) is accelerating diffusion of AI capabilities. This means even sectors or regions without top AI labs can adopt the technology and innovate on top of it, broadening the spillovers. Moreover , AI expertise and tools are becoming more democratized – there are now “no-code” or “low-code” AI platforms that let non-programmers leverage AI, thus more people can innovate with AI. All of this increases the generality and reach of the technology. In summary, AI is not a static invention; it is a fertile enabling platform that is generating new products, services, and methods across the board. From new startups built entirely around AI capabilities, to legacy industries transformed by AI-driven optimizations, the wave of complementary innovation is well underway. This is exactly what one expects from a general-purpose technology – not only does it improve itself, it causes other innovations to blossom . AI’s role in accelerating the pace of innovation and problem-solving in other domains underscores its GPT status. Trajectories and Forecasts: Continued Expansion and Proliferation If AI is truly a GPT, we should expect to see its use proliferating rapidly and its economic impact growing over time. Indeed, all indicators point to AI continuing on a steep adoption curve and becoming even more deeply embedded in the economy in coming years. Both current trends and future forecasts reinforce the view that AI’s influence is expanding (and will keep expanding) at an unprecedented scale. Adoption trends: Over the past decade, there has been a dramatic uptick in the adoption of AI by businesses and institutions. Surveys of corporate executives reveal that AI usage has jumped multifold. For instance, a global McKinsey survey found that the share of companies using AI in at least one business function more than doubled in five years – from only 20% of respondents in 2017 to about 50% by 202218 6 . In other words, within a relatively short time, AI went from a niche experiment at a few firms to mainstream: at least half of companies report using some AI, and in many cases multiple AI capabilities. (By 2023, despite a slight plateau at ~55%, plans to invest further in AI are widespread, indicating the next wave of adoption is imminent.) Moreover , those companies already using AI are scaling up their deployments – the average number of different AI capabilities or use cases implemented per company doubled between 2018 and 2022 (from ~2 to ~4) . This shows not just more firms trying AI, but each firm finding more areas to apply it. Importantly, most firms plan to keep increasing their investment in AI: 63% of respondents expected their AI spending to rise over the next three years, as of the 2022 survey . This broad-based commitment suggests AI’s presence in operations will deepen, much like how IT spread through every department in past decades. Soaring usage and diffusion: On the consumer side, the adoption of AI-powered applications has been nothing short of explosive. The clearest example is ChatGPT – a consumer-facing AI application which gained mass popularity. ChatGPT reached 100 million monthly active users in just two months after launch , making it the fastest-growing consumer app in history at the time . For comparison, it took years for services like Instagram or Netflix to hit that milestone. This spectacular growth indicates an enormous appetite and readiness of the public to use AI tools in daily life (for writing help, information, entertainment, etc.). It also exemplifies how quickly a useful AI can spread given today’s digital distribution: a powerful model can be made available to anyone with internet access almost instantly. Such rapid diffusion is a hallmark of GPTs in the modern era – with networked software delivery, AI can propagate at a speed unimaginable for earlier technologies (electricity needed wires in every house, by contrast). This trend will likely continue as new AI tools and assistants emerge and as existing ones (like voice assistants, translation apps, etc.) improve – we can expect hundreds of millions, eventually billions, of users interacting with AI regularly, which effectively integrates AI into the fabric of daily economic life worldwide. Workforce and task penetration: Studies suggest that AI’s impact will reach across a large portion of jobs and tasks, further underscoring its general-purpose nature. One prominent analysis (by OpenAI researchers and University of Pennsylvania economists) found that roughly 80% of the U.S. workforce could have at least 10% of their work tasks affected by AI , and nearly 19% of workers may see 50% or more of their tasks impacted by AI automation or augmentation . In plain terms, a vast majority of occupations will feel some effect of AI – whether it’s software to assist in drafting emails, AI systems handling customer queries, algorithms optimizing schedules, or machines taking over routine physical tasks. And for a significant subset of jobs, AI could transform a large share of the work. This kind of widespread task impact across white-collar and blue-collar jobs alike is another indicator of a GPT: just as electricity eventually touched almost every job (either by powering someone’s tools or lighting their workspace or driving the machines they use), AI is poised to touch almost every job in some manner . As AI capabilities advance (especially with new generative AI that can draft text, code, create images, etc.), its scope of impact on human work only broadens. This suggests a future where working alongside AI becomes as common as working with computers or electric machines – a strong sign of pervasive technological penetration. Economic growth and productivity: The ultimate mark of a GPT is its macroeconomic impact – does it significantly boost productivity and economic growth? While we are still in early days for measurable economy-wide impacts (and indeed the so-called “productivity J-curve” theory holds that benefits may lag initially as complementary investments are made ), forecasts are optimistic about AI’s contribution. Analysts have attempted to quantify AI’s potential effect on GDP in the coming decade, and the numbers are striking. PwC estimates that by 2030, AI could contribute up to $15.7 trillion to the global economy . That is roughly a 14% boost to global GDP – an impact larger than the current output of China and India19 20 21 22 23 24 25 7 combined . If realized, this would clearly mark AI as one of the greatest economic drivers of the century. Similarly, investment bank Goldman Sachs recently projected that generative AI alone could raise the annual GDP growth rate of the United States by about 0.4 percentage points over a 10-year period . A 0.4 pp increase may sound small, but at scale it is huge – it’s akin to adding trillions to the economy over a decade above baseline, and is comparable to the boosts attributed to past GPTs (for context, the steam engine and later electricity are credited with on the order of 0.3–0.8 pp annual GDP acceleration during their diffusion). These forecasts align with the intuition that AI can significantly raise productivity across many activities (through automation of routine tasks, decision support for complex tasks, and enabling new high-value activities). Speed of proliferation: Unlike past technologies that required building physical infrastructure (railroads, power lines, etc.), AI rides on existing digital infrastructure, which means its proliferation can be extremely rapid. As noted earlier , devices and internet connectivity are already widespread, so AI services can be rolled out at minimal cost. Additionally, AI systems often have a natural language interface (you talk or type to them in plain language), which lowers barriers to adoption – users do not need special training to use many AI tools, unlike, say, learning to operate complex machinery. This means diffusion is not bottlenecked by skill acquisition as severely; people can incorporate AI into their tasks relatively quickly. McAfee emphasizes that because of these factors, generative AI’s transformational effects will manifest faster than those of earlier GPTs . We are effectively leaping straight into broad usage because the complementary infrastructure (computers, smartphones, cloud platforms) and user familiarity with digital tools are already in place. This is a unique aspect of AI as a GPT in the 21st century – the ramp-up to impact can be much more compressed in time. All the above points to an inescapable conclusion: AI’s role in the economy is on a steep upward trajectory , consistent with it being a powerful GPT. Adoption is broad and growing, usage is sky-rocketing among individuals and firms, and projected economic contributions are enormous. Nations around the world have recognized this and are investing heavily in AI research and deployment, aware that leadership in AI could confer competitive advantages in productivity and innovation. (The ongoing U.S.–China strategic rivalry in AI development is often likened to a “tech arms race,” underlining that whichever country best diffuses and integrates AI across its economy might gain a substantial edge .) From a policy and strategy perspective, AI is treated not as a narrow tech, but as infrastructure for the next wave of growth – much as railways were national infrastructure in the 1800s or electrification in the 1900s. This consensus across industry, academia, and governments further reinforces that AI’s general-purpose nature and potential are widely acknowledged. Conclusion Considering the evidence, artificial intelligence unmistakably bears all the hallmarks of a general- purpose technology . The theoretical criteria are clearly met: AI is highly pervasive , with deep learning and reinforcement learning systems finding use in virtually every sector of the economy today, from healthcare and finance to manufacturing, retail, education, and beyond. It is continuously improving at a rapid rate , as seen in the striking leaps in AI capabilities over just the past few years and the declining cost of intelligence operations. AI is also spawning an ecosystem of complementary innovations – enabling new products, new business models, and new scientific breakthroughs that build on its capabilities, much as earlier GPTs enabled complementary industries (e.g. the automobile spurred suburbs, highways, drive-thru restaurants, etc.). Furthermore, AI’s largely digital, non-rival nature allows it to scale and diffuse faster than any prior technology, giving it an even greater transformative potential in a short time span. 26 16 2728 8 Empirical examples reinforce the argument: we have seen AI match or exceed human performance in tasks once thought untouchable (strategic games like Go, complex perceptual tasks like image recognition, creative tasks like composing text or art), and then translate those advances into practical tools that save energy, design better chips, accelerate drug discovery, and more. Such cross-domain impact is a signature of a GPT’s generality. At the same time, usage statistics and investment trends indicate that AI is becoming deeply ingrained in how we all work and live – millions of users and businesses have integrated AI into their routines, akin to how electric power or the internet became ubiquitous backbones of daily life. Forecasts by economists and analysts foresee AI driving a significant portion of productivity growth and economic value in the coming decades , which is exactly what one would expect from a true “engine of growth.” In light of these points, an economist assessing AI through the lens of GPT theory should indeed conclude that AI is clearly a general-purpose technology . It is not just a single-purpose innovation or a transient tech fad; it is a fundamental enabling platform with economy-wide reach and long-term impact. Like earlier GPTs, AI will likely require time and complementary investments to fully realize its productivity gains (organizations need to reorganize, workers need to learn to use AI, etc.), but the process is well underway. The historical pattern – initial adoption hurdles followed by a productivity boom – may be unfolding with AI as well, sometimes called the “productivity J-curve” effect . If that pattern holds, we can expect AI to substantially boost economic growth and living standards in the years ahead, just as electrification and computing eventually did after an adoption lag . In conclusion, by every reasonable definition and supported by growing empirical evidence, artificial intelligence qualifies as a general-purpose technology. Its general applicability, continuous advancement, and capacity to induce broad complementary innovations put it in the same league as the most transformative technologies in history. Economists and policymakers, therefore, view AI not in isolation but as a general engine that can drive economy-wide improvements. As AI continues to expand and proliferate, its GPT status will become only more pronounced – ushering in changes in how we produce, consume, and work that rival the industrial revolution’s scope. In the words of Andrew Ng, asking what AI is useful for is like asking what electricity is useful for – the answer is “almost everything” . Such is the hallmark of a general-purpose technology, and AI clearly fits the bill. Sources: Bresnahan, T. & Trajtenberg, M. (1996). General purpose technologies: “Engines of growth”? – Journal of Econometrics, 65 (1). (Criteria of GPTs: pervasiveness, improvement, innovation-spawning) . Lipsey, R. G. & Carlaw, K. (2005). General Purpose Technologies in Theory and Practice. (Definition of GPT as single generic technology, widely used with many uses and spillovers) . Ng, Andrew (2023). U.S. Senate AI Insight Forum – Written Statement. (Describes AI as a general- purpose technology akin to electricity/internet; lists diverse current use cases of AI across sectors) . World Economic Forum / Business Insider (2016). Google DeepMind AI reduces data centre cooling energy by 40%. (Example of AI [DeepMind] optimizing Google’s data center operations, achieving 40% energy reduction in cooling) . World Economic Forum (2025). How AI-powered innovation can democratize breakthrough science. (Notes that DeepMind’s AlphaFold solved protein folding, a 50-year grand challenge, unlocking major opportunities in drug discovery and materials science) . 2526 24 2926 1 • 4 • 5 • 1 • 8 • 11 9 Google DeepMind (2024). How AlphaChip transformed computer chip design. (Reinforcement learning used to produce superhuman chip designs in hours; AlphaChip’s layouts deployed in real-world hardware globally) . MIT Sloan (2024). The impact of generative AI as a general-purpose technology. (McAfee’s analysis: generative AI shows rapid improvement and pervasive adoption; e.g. GPT-4 vs GPT-3.5 performance on bar exam, 80% of jobs seeing some AI impact; generative AI meets GPT criteria of improvement, pervasiveness, complementary innovation) . MIT Sloan (2024). The impact of generative AI... (Goldman Sachs estimate that generative AI will boost US GDP growth by ~0.4 percentage points annually over the next decade) . World Economic Forum (2019, citing PwC). By 2030, AI will contribute $15 trillion to the global economy. (Forecast that AI could add $15.7 trillion, or 14% increase, to global GDP by 2030) . Reuters (2023). ChatGPT sets record for fastest-growing user base. (ChatGPT hit 100 million users in 2 months, fastest adoption of any consumer app, illustrating rapid AI diffusion) . McKinsey & Co. (2022). State of AI survey. (Corporate AI adoption rose from 20% of firms in 2017 to ~50% in 2022; companies doubling the number of AI capabilities used; majority plan to increase AI investment further) . Hacking Economics (2023). The Economics of Infinite Intelligence. (Economic analysis noting AI makes intelligence a non-rival good with near-zero marginal cost, enabling unlimited use of knowledge without additional cost) . • 12 • 132330 • 26 • 25 • 22 • 192021 • 6 10 Written Statement of Andrew Ng Before the U.S. Senate AI Insight Forum - AI Fund https://aifund.ai/insights/insights-written-statement-of-andrew-ng-before-the-u-s-senate-ai-insight-forum/ C:\Working Papers\11093.wpd https://www.nber .org/system/files/working_papers/w11093/w11093.pdf General-purpose technology - Wikipedia https://en.wikipedia.org/wiki/General-purpose_technology The Economics of Infinite Intelligence: Zero-Cost Innovation and Business Model Disruption https://www.hackingeconomics.com/p/the-economics-of-infinite-intelligence Google harnesses the power of AI to cut energy use | World Economic Forum https://www.weforum.org/stories/2016/07/google-harnesses-the-power-of-ai-to-cut-energy-use/ AI-powered innovation can democratize breakthrough science | World Economic Forum https://www.weforum.org/stories/2025/06/ai-innovation-democratizes-breakthrough-science/ How AlphaChip transformed computer chip design - Google DeepMind https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/ The impact of generative AI as a general-purpose technology | MIT Sloan https://mitsloan.mit.edu/ideas-made-to-matter/impact-generative-ai-a-general-purpose-technology The state of AI in 2022—and a half decade in review | McKinsey https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review ChatGPT sets record for fastest-growing user base - analyst note | Reuters https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/ By 2030, AI will contribute $15 trillion to the global economy | World Economic Forum https://www.weforum.org/stories/2019/08/by-2030-ai-will-contribute-15-trillion-to-the-global-economy/ General-Purpose Technology and the Dominance of Nations https://www.orfonline.org/research/general-purpose-technology-and-the-dominance-of-nations Five Key Issues to Watch in AI in 2025 - CSET https://cset.georgetown.edu/article/five-key-issues-to-watch-in-ai-in-2025/1 7 910 2 4 3 524 29 6 8 11 12 13 14 15 16 17 18 23 26 30 19 20 21 22 25 27 28 11